{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8525473f-45af-46d7-ad45-a8e99ffdeaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-28 08:49:43.632281: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-09-28 08:49:43.632308: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PreProcessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scalertrain = MinMaxScaler(feature_range=(0,1))\n",
    "scalertest = MinMaxScaler(feature_range=(0,1))\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Input, LSTM, Dropout\n",
    "from keras import regularizers\n",
    "import math\n",
    "import statistics\n",
    "import datetime\n",
    "from pyFTS.common import Util\n",
    "from pyFTS.benchmarks import Measures\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c7bba0a-9780-408a-9f2e-47f8fcbaeee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('energydata_complete.csv')\n",
    "test = PreProcessing.PreProcessing(df, 'Appliances')\n",
    "test.clean(['index', 'date','rv1','rv2','T9','T6','Windspeed'])\n",
    "test.shift(1,1)\n",
    "data = test.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2849c91b-9d99-4b53-b9ed-a253f23173b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 60],\n",
       "       [ 50],\n",
       "       [ 50],\n",
       "       ...,\n",
       "       [270],\n",
       "       [420],\n",
       "       [430]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Appliances(t)'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bb38bbb-b38d-4d76-a3fb-a786bf4522b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_LSTM(data,n_windows,train_size): \n",
    "    result = {\n",
    "         \"window\": [],\n",
    "         \"rmse\": [],\n",
    "         \"mape\": [],\n",
    "         \"smape\": [],\n",
    "         \"mae\": []\n",
    "    }\n",
    "\n",
    "    order = 1\n",
    "    tam = len(data)\n",
    "    n_windows = 30\n",
    "    windows_length = math.floor(tam / n_windows)\n",
    "    for ct, ttrain, ttest in Util.sliding_window(data, windows_length, 0.75, inc=1):\n",
    "        if len(ttest) > 0:\n",
    "        \n",
    "            X_train = ttrain.loc[:,'Appliances(t-1)':'Tdewpoint(t-1)']\n",
    "            X_test = ttest.loc[:,'Appliances(t-1)':'Tdewpoint(t-1)']\n",
    "            y_train = ttrain['Appliances(t)']\n",
    "            y_test = ttest['Appliances(t)']\n",
    "            \n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.fit_transform(X_test)\n",
    "            y_train = scalertrain.fit_transform(y_train.values.reshape(-1,1))\n",
    "            y_test = scalertest.fit_transform(y_test.values.reshape(-1,1))\n",
    "            \n",
    "            X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "            X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "            y_train = y_train.reshape((y_train.shape[0], 1))\n",
    "            y_test = y_test.reshape((y_test.shape[0], 1))\n",
    "            \n",
    "        \n",
    "            print('-' * 20)\n",
    "            print(f'training window {(ct)}')\n",
    "            \n",
    "            # design network\n",
    "            from keras.callbacks import EarlyStopping\n",
    "            model = Sequential()\n",
    "            model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True, activity_regularizer=regularizers.l2(10e-5),\n",
    "               activation='relu', kernel_regularizer=regularizers.l1(10e-5), recurrent_regularizer = regularizers.l2(10e-5)))\n",
    "            model.add(LSTM(30, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True, activation='relu'))\n",
    "            model.add(LSTM(10, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False, activation='relu'))\n",
    "#model.add(LSTM(5, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=False, activation='relu'))\n",
    "#model.add(LSTM(1, input_shape=(train_X.shape[1], train_X.shape[2]))) \n",
    "#model.add(Dropout(0.2))\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "            model.compile(loss='mse', optimizer='adam',metrics=['mse'])\n",
    "\n",
    "            epochs = 75\n",
    "            batch_size=10\n",
    "            import matplotlib.pyplot as plt\n",
    "            history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_split=0.2,  shuffle=False)\n",
    "            yhat = model.predict(X_test)\n",
    "            \n",
    "            y_test = scalertest.inverse_transform(y_test)\n",
    "            forecast = scalertest.inverse_transform(yhat)\n",
    "            \n",
    "            \n",
    "            print(\"[{0: %H:%M:%S}]\".format(datetime.datetime.now()) + f\" getting statistics\")\n",
    "            rmse = Measures.rmse(y_test,forecast)\n",
    "            mape = Measures.mape(y_test,forecast)\n",
    "            smape = Measures.smape(y_test,forecast)\n",
    "        \n",
    "            forecast = pd.DataFrame(forecast)\n",
    "            forecast.fillna(forecast.mean(),inplace=True)\n",
    "            forecast = np.array(forecast).reshape(-1)\n",
    "            mae = mean_absolute_error(y_test, forecast)\n",
    "\n",
    "        \n",
    "            result[\"rmse\"].append(rmse)\n",
    "            result[\"mape\"].append(mape)\n",
    "            result[\"smape\"].append(smape)\n",
    "            result[\"mae\"].append(mae)\n",
    "            result[\"window\"].append(ct)\n",
    "        \n",
    "            \n",
    "    measures = pd.DataFrame(result)\n",
    "    return measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add8c1c9-a9f1-4734-8f1d-3f5eeb186761",
   "metadata": {},
   "outputs": [],
   "source": [
    "meas = sliding_window_LSTM(data,30,0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89e2a1cc-9e7b-40c7-84e8-e17717a1c4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = meas\n",
    "rmse = round(statistics.mean(measures['rmse']),3)\n",
    "mape = round(statistics.mean(measures['mape']),3)\n",
    "smape = round(statistics.mean(measures['smape']),3)\n",
    "mae = round(statistics.mean(measures['mae']),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45972bb7-474d-42ef-b238-a8cd3489fe7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.329\n",
      "44.748\n",
      "19.341\n",
      "42.59\n"
     ]
    }
   ],
   "source": [
    "print (rmse)\n",
    "print (mape)\n",
    "print (smape)\n",
    "print (mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53803d77-29c6-40cb-93e2-11176f462a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (0,27) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>use [kW]</th>\n",
       "      <th>gen [kW]</th>\n",
       "      <th>Dishwasher [kW]</th>\n",
       "      <th>Furnace 1 [kW]</th>\n",
       "      <th>Furnace 2 [kW]</th>\n",
       "      <th>Home office [kW]</th>\n",
       "      <th>Fridge [kW]</th>\n",
       "      <th>Wine cellar [kW]</th>\n",
       "      <th>Garage door [kW]</th>\n",
       "      <th>Kitchen 12 [kW]</th>\n",
       "      <th>...</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>visibility</th>\n",
       "      <th>apparentTemperature</th>\n",
       "      <th>pressure</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>windBearing</th>\n",
       "      <th>precipIntensity</th>\n",
       "      <th>dewPoint</th>\n",
       "      <th>precipProbability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.932833</td>\n",
       "      <td>0.003483</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.061917</td>\n",
       "      <td>0.442633</td>\n",
       "      <td>0.124150</td>\n",
       "      <td>0.006983</td>\n",
       "      <td>0.013083</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>...</td>\n",
       "      <td>36.14</td>\n",
       "      <td>0.62</td>\n",
       "      <td>10.00</td>\n",
       "      <td>29.26</td>\n",
       "      <td>1016.91</td>\n",
       "      <td>9.18</td>\n",
       "      <td>282.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>24.40</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.585083</td>\n",
       "      <td>0.003417</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.022100</td>\n",
       "      <td>0.678733</td>\n",
       "      <td>0.440200</td>\n",
       "      <td>0.121450</td>\n",
       "      <td>0.007433</td>\n",
       "      <td>0.013583</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>...</td>\n",
       "      <td>36.14</td>\n",
       "      <td>0.62</td>\n",
       "      <td>10.00</td>\n",
       "      <td>29.26</td>\n",
       "      <td>1016.91</td>\n",
       "      <td>9.18</td>\n",
       "      <td>282.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>24.40</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.533817</td>\n",
       "      <td>0.003450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020633</td>\n",
       "      <td>0.062967</td>\n",
       "      <td>0.270033</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>0.007033</td>\n",
       "      <td>0.013117</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>...</td>\n",
       "      <td>36.14</td>\n",
       "      <td>0.62</td>\n",
       "      <td>10.00</td>\n",
       "      <td>29.26</td>\n",
       "      <td>1016.91</td>\n",
       "      <td>9.18</td>\n",
       "      <td>282.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>24.40</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.190950</td>\n",
       "      <td>0.003083</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.387400</td>\n",
       "      <td>0.061883</td>\n",
       "      <td>0.256867</td>\n",
       "      <td>0.004933</td>\n",
       "      <td>0.101783</td>\n",
       "      <td>0.012533</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>...</td>\n",
       "      <td>36.14</td>\n",
       "      <td>0.62</td>\n",
       "      <td>10.00</td>\n",
       "      <td>29.26</td>\n",
       "      <td>1016.91</td>\n",
       "      <td>9.18</td>\n",
       "      <td>282.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>24.40</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.582083</td>\n",
       "      <td>0.003067</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.022050</td>\n",
       "      <td>0.681717</td>\n",
       "      <td>0.242433</td>\n",
       "      <td>0.005550</td>\n",
       "      <td>0.122400</td>\n",
       "      <td>0.013550</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>...</td>\n",
       "      <td>36.14</td>\n",
       "      <td>0.62</td>\n",
       "      <td>10.00</td>\n",
       "      <td>29.26</td>\n",
       "      <td>1016.91</td>\n",
       "      <td>9.18</td>\n",
       "      <td>282.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>24.40</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503860</th>\n",
       "      <td>1.621417</td>\n",
       "      <td>0.004183</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.441950</td>\n",
       "      <td>0.645467</td>\n",
       "      <td>0.041767</td>\n",
       "      <td>0.129317</td>\n",
       "      <td>0.008067</td>\n",
       "      <td>0.012883</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>...</td>\n",
       "      <td>35.12</td>\n",
       "      <td>0.86</td>\n",
       "      <td>8.74</td>\n",
       "      <td>29.45</td>\n",
       "      <td>1011.49</td>\n",
       "      <td>6.72</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>31.27</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503870</th>\n",
       "      <td>0.896250</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.496633</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>0.042317</td>\n",
       "      <td>0.123800</td>\n",
       "      <td>0.007850</td>\n",
       "      <td>0.012433</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>...</td>\n",
       "      <td>35.12</td>\n",
       "      <td>0.86</td>\n",
       "      <td>8.74</td>\n",
       "      <td>29.45</td>\n",
       "      <td>1011.49</td>\n",
       "      <td>6.72</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>31.27</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503880</th>\n",
       "      <td>1.311617</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.359167</td>\n",
       "      <td>0.645433</td>\n",
       "      <td>0.041917</td>\n",
       "      <td>0.005133</td>\n",
       "      <td>0.008167</td>\n",
       "      <td>0.013083</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>...</td>\n",
       "      <td>35.12</td>\n",
       "      <td>0.86</td>\n",
       "      <td>8.74</td>\n",
       "      <td>29.45</td>\n",
       "      <td>1011.49</td>\n",
       "      <td>6.72</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>31.27</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503890</th>\n",
       "      <td>2.059367</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.153367</td>\n",
       "      <td>0.643300</td>\n",
       "      <td>0.042050</td>\n",
       "      <td>0.005117</td>\n",
       "      <td>0.008283</td>\n",
       "      <td>0.013267</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>...</td>\n",
       "      <td>35.12</td>\n",
       "      <td>0.86</td>\n",
       "      <td>8.74</td>\n",
       "      <td>29.45</td>\n",
       "      <td>1011.49</td>\n",
       "      <td>6.72</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>31.27</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503900</th>\n",
       "      <td>1.522583</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.023033</td>\n",
       "      <td>0.627233</td>\n",
       "      <td>0.041767</td>\n",
       "      <td>0.005283</td>\n",
       "      <td>0.008433</td>\n",
       "      <td>0.013533</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>...</td>\n",
       "      <td>35.12</td>\n",
       "      <td>0.86</td>\n",
       "      <td>8.74</td>\n",
       "      <td>29.45</td>\n",
       "      <td>1011.49</td>\n",
       "      <td>6.72</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>31.27</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50391 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        use [kW]  gen [kW]  Dishwasher [kW]  Furnace 1 [kW]  Furnace 2 [kW]  \\\n",
       "0       0.932833  0.003483         0.000033        0.020700        0.061917   \n",
       "10      1.585083  0.003417         0.000050        0.022100        0.678733   \n",
       "20      0.533817  0.003450         0.000000        0.020633        0.062967   \n",
       "30      1.190950  0.003083         0.000217        0.387400        0.061883   \n",
       "40      1.582083  0.003067         0.000050        0.022050        0.681717   \n",
       "...          ...       ...              ...             ...             ...   \n",
       "503860  1.621417  0.004183         0.000033        0.441950        0.645467   \n",
       "503870  0.896250  0.004150         0.000233        0.496633        0.063000   \n",
       "503880  1.311617  0.004167         0.000017        0.359167        0.645433   \n",
       "503890  2.059367  0.003383         0.000033        0.153367        0.643300   \n",
       "503900  1.522583  0.003200         0.000067        0.023033        0.627233   \n",
       "\n",
       "        Home office [kW]  Fridge [kW]  Wine cellar [kW]  Garage door [kW]  \\\n",
       "0               0.442633     0.124150          0.006983          0.013083   \n",
       "10              0.440200     0.121450          0.007433          0.013583   \n",
       "20              0.270033     0.004950          0.007033          0.013117   \n",
       "30              0.256867     0.004933          0.101783          0.012533   \n",
       "40              0.242433     0.005550          0.122400          0.013550   \n",
       "...                  ...          ...               ...               ...   \n",
       "503860          0.041767     0.129317          0.008067          0.012883   \n",
       "503870          0.042317     0.123800          0.007850          0.012433   \n",
       "503880          0.041917     0.005133          0.008167          0.013083   \n",
       "503890          0.042050     0.005117          0.008283          0.013267   \n",
       "503900          0.041767     0.005283          0.008433          0.013533   \n",
       "\n",
       "        Kitchen 12 [kW]  ...  temperature  humidity  visibility  \\\n",
       "0              0.000417  ...        36.14      0.62       10.00   \n",
       "10             0.000350  ...        36.14      0.62       10.00   \n",
       "20             0.000750  ...        36.14      0.62       10.00   \n",
       "30             0.000700  ...        36.14      0.62       10.00   \n",
       "40             0.000567  ...        36.14      0.62       10.00   \n",
       "...                 ...  ...          ...       ...         ...   \n",
       "503860         0.000317  ...        35.12      0.86        8.74   \n",
       "503870         0.000467  ...        35.12      0.86        8.74   \n",
       "503880         0.000650  ...        35.12      0.86        8.74   \n",
       "503890         0.000433  ...        35.12      0.86        8.74   \n",
       "503900         0.000467  ...        35.12      0.86        8.74   \n",
       "\n",
       "        apparentTemperature  pressure  windSpeed  windBearing  \\\n",
       "0                     29.26   1016.91       9.18        282.0   \n",
       "10                    29.26   1016.91       9.18        282.0   \n",
       "20                    29.26   1016.91       9.18        282.0   \n",
       "30                    29.26   1016.91       9.18        282.0   \n",
       "40                    29.26   1016.91       9.18        282.0   \n",
       "...                     ...       ...        ...          ...   \n",
       "503860                29.45   1011.49       6.72        186.0   \n",
       "503870                29.45   1011.49       6.72        186.0   \n",
       "503880                29.45   1011.49       6.72        186.0   \n",
       "503890                29.45   1011.49       6.72        186.0   \n",
       "503900                29.45   1011.49       6.72        186.0   \n",
       "\n",
       "        precipIntensity  dewPoint  precipProbability  \n",
       "0                0.0000     24.40               0.00  \n",
       "10               0.0000     24.40               0.00  \n",
       "20               0.0000     24.40               0.00  \n",
       "30               0.0000     24.40               0.00  \n",
       "40               0.0000     24.40               0.00  \n",
       "...                 ...       ...                ...  \n",
       "503860           0.0101     31.27               0.51  \n",
       "503870           0.0101     31.27               0.51  \n",
       "503880           0.0101     31.27               0.51  \n",
       "503890           0.0101     31.27               0.51  \n",
       "503900           0.0101     31.27               0.51  \n",
       "\n",
       "[50391 rows x 27 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('HomeC.csv')\n",
    "data = df.drop(labels=['icon','summary','cloudCover', 'House overall [kW]', 'time'], axis=1)\n",
    "data = data.loc[0: : 10]\n",
    "data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd9b1bbb-03e2-4b72-a085-b6610606767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_LSTM(data,n_windows,train_size): \n",
    "    result = {\n",
    "         \"window\": [],\n",
    "         \"rmse\": [],\n",
    "         \"mape\": [],\n",
    "         \"smape\": [],\n",
    "         \"mae\": []\n",
    "    }\n",
    "\n",
    "    order = 1\n",
    "    tam = len(data)\n",
    "    n_windows = 30\n",
    "    windows_length = math.floor(tam / n_windows)\n",
    "    for ct, ttrain, ttest in Util.sliding_window(data, windows_length, 0.75, inc=1):\n",
    "        if len(ttest) > 0:\n",
    "        \n",
    "            X_train = ttrain.loc[:,'gen [kW]':'precipProbability']\n",
    "            X_test = ttest.loc[:,'gen [kW]':'precipProbability']\n",
    "            y_train = ttrain['use [kW]']\n",
    "            y_test = ttest['use [kW]']\n",
    "            \n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.fit_transform(X_test)\n",
    "            y_train = scalertrain.fit_transform(y_train.values.reshape(-1,1))\n",
    "            y_test = scalertest.fit_transform(y_test.values.reshape(-1,1))\n",
    "            \n",
    "            X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "            X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "            y_train = y_train.reshape((y_train.shape[0], 1))\n",
    "            y_test = y_test.reshape((y_test.shape[0], 1))\n",
    "            \n",
    "        \n",
    "            print('-' * 20)\n",
    "            print(f'training window {(ct)}')\n",
    "            \n",
    "            # design network\n",
    "            from keras.callbacks import EarlyStopping\n",
    "            model = Sequential()\n",
    "            model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True, activity_regularizer=regularizers.l2(10e-5),\n",
    "               activation='relu', kernel_regularizer=regularizers.l1(10e-5), recurrent_regularizer = regularizers.l2(10e-5)))\n",
    "            model.add(LSTM(30, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True, activation='relu'))\n",
    "            model.add(LSTM(10, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False, activation='relu'))\n",
    "#model.add(LSTM(5, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=False, activation='relu'))\n",
    "#model.add(LSTM(1, input_shape=(train_X.shape[1], train_X.shape[2]))) \n",
    "#model.add(Dropout(0.2))\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "            model.compile(loss='mse', optimizer='adam',metrics=['mse'])\n",
    "\n",
    "            epochs = 70\n",
    "            batch_size=10\n",
    "            import matplotlib.pyplot as plt\n",
    "            history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_split=0.2,  shuffle=False)\n",
    "            yhat = model.predict(X_test)\n",
    "            \n",
    "            y_test = scalertest.inverse_transform(y_test)\n",
    "            forecast = scalertest.inverse_transform(yhat)\n",
    "            \n",
    "            \n",
    "            print(\"[{0: %H:%M:%S}]\".format(datetime.datetime.now()) + f\" getting statistics\")\n",
    "            rmse = Measures.rmse(y_test,forecast)\n",
    "            mape = Measures.mape(y_test,forecast)\n",
    "            smape = Measures.smape(y_test,forecast)\n",
    "        \n",
    "            forecast = pd.DataFrame(forecast)\n",
    "            forecast.fillna(forecast.mean(),inplace=True)\n",
    "            forecast = np.array(forecast).reshape(-1)\n",
    "            mae = mean_absolute_error(y_test, forecast)\n",
    "\n",
    "        \n",
    "            result[\"rmse\"].append(rmse)\n",
    "            result[\"mape\"].append(mape)\n",
    "            result[\"smape\"].append(smape)\n",
    "            result[\"mae\"].append(mae)\n",
    "            result[\"window\"].append(ct)\n",
    "        \n",
    "            \n",
    "    measures = pd.DataFrame(result)\n",
    "    return measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c356cf53-43ca-46d6-9f80-af86f0971485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0142 - mse: 0.0101 - val_loss: 0.0131 - val_mse: 0.0090\n",
      "Epoch 8/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0136 - mse: 0.0097 - val_loss: 0.0128 - val_mse: 0.0089\n",
      "Epoch 9/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0131 - mse: 0.0093 - val_loss: 0.0124 - val_mse: 0.0087\n",
      "Epoch 10/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0126 - mse: 0.0090 - val_loss: 0.0122 - val_mse: 0.0085\n",
      "Epoch 11/70\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0122 - mse: 0.0087 - val_loss: 0.0119 - val_mse: 0.0083\n",
      "Epoch 12/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0119 - mse: 0.0084 - val_loss: 0.0116 - val_mse: 0.0081\n",
      "Epoch 13/70\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0116 - mse: 0.0082 - val_loss: 0.0113 - val_mse: 0.0079\n",
      "Epoch 14/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0113 - mse: 0.0080 - val_loss: 0.0111 - val_mse: 0.0077\n",
      "Epoch 15/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0110 - mse: 0.0078 - val_loss: 0.0108 - val_mse: 0.0075\n",
      "Epoch 16/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0108 - mse: 0.0076 - val_loss: 0.0106 - val_mse: 0.0073\n",
      "Epoch 17/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0106 - mse: 0.0074 - val_loss: 0.0104 - val_mse: 0.0071\n",
      "Epoch 18/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0104 - mse: 0.0072 - val_loss: 0.0101 - val_mse: 0.0069\n",
      "Epoch 19/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0102 - mse: 0.0070 - val_loss: 0.0099 - val_mse: 0.0067\n",
      "Epoch 20/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0100 - mse: 0.0069 - val_loss: 0.0097 - val_mse: 0.0065\n",
      "Epoch 21/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0098 - mse: 0.0067 - val_loss: 0.0095 - val_mse: 0.0064\n",
      "Epoch 22/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0096 - mse: 0.0066 - val_loss: 0.0093 - val_mse: 0.0063\n",
      "Epoch 23/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0094 - mse: 0.0065 - val_loss: 0.0092 - val_mse: 0.0061\n",
      "Epoch 24/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0093 - mse: 0.0063 - val_loss: 0.0090 - val_mse: 0.0060\n",
      "Epoch 25/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0091 - mse: 0.0062 - val_loss: 0.0089 - val_mse: 0.0059\n",
      "Epoch 26/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0089 - mse: 0.0061 - val_loss: 0.0087 - val_mse: 0.0058\n",
      "Epoch 27/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0060 - val_loss: 0.0086 - val_mse: 0.0058\n",
      "Epoch 28/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0086 - mse: 0.0059 - val_loss: 0.0085 - val_mse: 0.0057\n",
      "Epoch 29/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0085 - mse: 0.0058 - val_loss: 0.0083 - val_mse: 0.0056\n",
      "Epoch 30/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0083 - mse: 0.0057 - val_loss: 0.0082 - val_mse: 0.0056\n",
      "Epoch 31/70\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0082 - mse: 0.0056 - val_loss: 0.0081 - val_mse: 0.0055\n",
      "Epoch 32/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0081 - mse: 0.0056 - val_loss: 0.0080 - val_mse: 0.0055\n",
      "Epoch 33/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0080 - mse: 0.0055 - val_loss: 0.0079 - val_mse: 0.0055\n",
      "Epoch 34/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0079 - mse: 0.0055 - val_loss: 0.0079 - val_mse: 0.0054\n",
      "Epoch 35/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0078 - mse: 0.0055 - val_loss: 0.0078 - val_mse: 0.0054\n",
      "Epoch 36/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0077 - mse: 0.0054 - val_loss: 0.0077 - val_mse: 0.0054\n",
      "Epoch 37/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0076 - mse: 0.0054 - val_loss: 0.0076 - val_mse: 0.0054\n",
      "Epoch 38/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0075 - mse: 0.0054 - val_loss: 0.0076 - val_mse: 0.0054\n",
      "Epoch 39/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0075 - mse: 0.0053 - val_loss: 0.0075 - val_mse: 0.0053\n",
      "Epoch 40/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0074 - mse: 0.0053 - val_loss: 0.0074 - val_mse: 0.0053\n",
      "Epoch 41/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0073 - mse: 0.0053 - val_loss: 0.0074 - val_mse: 0.0053\n",
      "Epoch 42/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0072 - mse: 0.0052 - val_loss: 0.0073 - val_mse: 0.0053\n",
      "Epoch 43/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0072 - mse: 0.0052 - val_loss: 0.0072 - val_mse: 0.0052\n",
      "Epoch 44/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0071 - mse: 0.0052 - val_loss: 0.0072 - val_mse: 0.0052\n",
      "Epoch 45/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0070 - mse: 0.0051 - val_loss: 0.0071 - val_mse: 0.0052\n",
      "Epoch 46/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0070 - mse: 0.0051 - val_loss: 0.0071 - val_mse: 0.0052\n",
      "Epoch 47/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0069 - mse: 0.0051 - val_loss: 0.0070 - val_mse: 0.0052\n",
      "Epoch 48/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0069 - mse: 0.0051 - val_loss: 0.0070 - val_mse: 0.0052\n",
      "Epoch 49/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0068 - mse: 0.0051 - val_loss: 0.0070 - val_mse: 0.0052\n",
      "Epoch 50/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0068 - mse: 0.0050 - val_loss: 0.0070 - val_mse: 0.0052\n",
      "Epoch 51/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0067 - mse: 0.0050 - val_loss: 0.0069 - val_mse: 0.0052\n",
      "Epoch 52/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0066 - mse: 0.0050 - val_loss: 0.0069 - val_mse: 0.0052\n",
      "Epoch 53/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0066 - mse: 0.0050 - val_loss: 0.0069 - val_mse: 0.0052\n",
      "Epoch 54/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0066 - mse: 0.0049 - val_loss: 0.0068 - val_mse: 0.0052\n",
      "Epoch 55/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0065 - mse: 0.0049 - val_loss: 0.0068 - val_mse: 0.0052\n",
      "Epoch 56/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0065 - mse: 0.0049 - val_loss: 0.0068 - val_mse: 0.0052\n",
      "Epoch 57/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0064 - mse: 0.0049 - val_loss: 0.0068 - val_mse: 0.0052\n",
      "Epoch 58/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0064 - mse: 0.0049 - val_loss: 0.0067 - val_mse: 0.0052\n",
      "Epoch 59/70\n",
      "101/101 [==============================] - 1s 8ms/step - loss: 0.0063 - mse: 0.0048 - val_loss: 0.0067 - val_mse: 0.0052\n",
      "Epoch 60/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0063 - mse: 0.0048 - val_loss: 0.0067 - val_mse: 0.0052\n",
      "Epoch 61/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0063 - mse: 0.0048 - val_loss: 0.0066 - val_mse: 0.0052\n",
      "Epoch 62/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0062 - mse: 0.0048 - val_loss: 0.0066 - val_mse: 0.0052\n",
      "Epoch 63/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0062 - mse: 0.0048 - val_loss: 0.0066 - val_mse: 0.0052\n",
      "Epoch 64/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0062 - mse: 0.0048 - val_loss: 0.0066 - val_mse: 0.0052\n",
      "Epoch 65/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0061 - mse: 0.0047 - val_loss: 0.0065 - val_mse: 0.0051\n",
      "Epoch 66/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0061 - mse: 0.0047 - val_loss: 0.0065 - val_mse: 0.0051\n",
      "Epoch 67/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0061 - mse: 0.0047 - val_loss: 0.0065 - val_mse: 0.0051\n",
      "Epoch 68/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0060 - mse: 0.0047 - val_loss: 0.0065 - val_mse: 0.0051\n",
      "Epoch 69/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0060 - mse: 0.0046 - val_loss: 0.0064 - val_mse: 0.0051\n",
      "Epoch 70/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0060 - mse: 0.0047 - val_loss: 0.0064 - val_mse: 0.0051\n",
      "[ 09:16:27] getting statistics\n",
      "--------------------\n",
      "training window 41975\n",
      "Epoch 1/70\n",
      "101/101 [==============================] - 5s 7ms/step - loss: 0.1565 - mse: 0.1322 - val_loss: 0.0906 - val_mse: 0.0816\n",
      "Epoch 2/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0283 - mse: 0.0211 - val_loss: 0.0205 - val_mse: 0.0157\n",
      "Epoch 3/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0168 - mse: 0.0124 - val_loss: 0.0184 - val_mse: 0.0145\n",
      "Epoch 4/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0154 - mse: 0.0115 - val_loss: 0.0173 - val_mse: 0.0138\n",
      "Epoch 5/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0146 - mse: 0.0109 - val_loss: 0.0166 - val_mse: 0.0132\n",
      "Epoch 6/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0140 - mse: 0.0105 - val_loss: 0.0160 - val_mse: 0.0127\n",
      "Epoch 7/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0135 - mse: 0.0101 - val_loss: 0.0154 - val_mse: 0.0122\n",
      "Epoch 8/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0131 - mse: 0.0098 - val_loss: 0.0149 - val_mse: 0.0116\n",
      "Epoch 9/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0128 - mse: 0.0094 - val_loss: 0.0143 - val_mse: 0.0111\n",
      "Epoch 10/70\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0125 - mse: 0.0091 - val_loss: 0.0138 - val_mse: 0.0106\n",
      "Epoch 11/70\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0121 - mse: 0.0088 - val_loss: 0.0133 - val_mse: 0.0101\n",
      "Epoch 12/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0118 - mse: 0.0086 - val_loss: 0.0128 - val_mse: 0.0096\n",
      "Epoch 13/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0115 - mse: 0.0083 - val_loss: 0.0123 - val_mse: 0.0091\n",
      "Epoch 14/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0112 - mse: 0.0080 - val_loss: 0.0118 - val_mse: 0.0086\n",
      "Epoch 15/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0109 - mse: 0.0077 - val_loss: 0.0113 - val_mse: 0.0082\n",
      "Epoch 16/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0106 - mse: 0.0074 - val_loss: 0.0109 - val_mse: 0.0078\n",
      "Epoch 17/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0103 - mse: 0.0071 - val_loss: 0.0106 - val_mse: 0.0074\n",
      "Epoch 18/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0100 - mse: 0.0068 - val_loss: 0.0102 - val_mse: 0.0071\n",
      "Epoch 19/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0097 - mse: 0.0065 - val_loss: 0.0098 - val_mse: 0.0068\n",
      "Epoch 20/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0094 - mse: 0.0063 - val_loss: 0.0095 - val_mse: 0.0065\n",
      "Epoch 21/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0091 - mse: 0.0060 - val_loss: 0.0092 - val_mse: 0.0062\n",
      "Epoch 22/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0088 - mse: 0.0057 - val_loss: 0.0089 - val_mse: 0.0059\n",
      "Epoch 23/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0085 - mse: 0.0055 - val_loss: 0.0086 - val_mse: 0.0057\n",
      "Epoch 24/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0082 - mse: 0.0052 - val_loss: 0.0083 - val_mse: 0.0055\n",
      "Epoch 25/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0078 - mse: 0.0050 - val_loss: 0.0081 - val_mse: 0.0053\n",
      "Epoch 26/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0075 - mse: 0.0047 - val_loss: 0.0078 - val_mse: 0.0051\n",
      "Epoch 27/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0072 - mse: 0.0045 - val_loss: 0.0076 - val_mse: 0.0049\n",
      "Epoch 28/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0068 - mse: 0.0042 - val_loss: 0.0074 - val_mse: 0.0048\n",
      "Epoch 29/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0065 - mse: 0.0040 - val_loss: 0.0072 - val_mse: 0.0047\n",
      "Epoch 30/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0062 - mse: 0.0037 - val_loss: 0.0070 - val_mse: 0.0046\n",
      "Epoch 31/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0059 - mse: 0.0036 - val_loss: 0.0069 - val_mse: 0.0046\n",
      "Epoch 32/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0057 - mse: 0.0034 - val_loss: 0.0068 - val_mse: 0.0046\n",
      "Epoch 33/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0055 - mse: 0.0033 - val_loss: 0.0067 - val_mse: 0.0046\n",
      "Epoch 34/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0054 - mse: 0.0032 - val_loss: 0.0067 - val_mse: 0.0047\n",
      "Epoch 35/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0053 - mse: 0.0032 - val_loss: 0.0067 - val_mse: 0.0048\n",
      "Epoch 36/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0051 - mse: 0.0031 - val_loss: 0.0067 - val_mse: 0.0048\n",
      "Epoch 37/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0050 - mse: 0.0031 - val_loss: 0.0067 - val_mse: 0.0049\n",
      "Epoch 38/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0049 - mse: 0.0031 - val_loss: 0.0067 - val_mse: 0.0049\n",
      "Epoch 39/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0049 - mse: 0.0030 - val_loss: 0.0067 - val_mse: 0.0050\n",
      "Epoch 40/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0048 - mse: 0.0030 - val_loss: 0.0067 - val_mse: 0.0050\n",
      "Epoch 41/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0047 - mse: 0.0030 - val_loss: 0.0066 - val_mse: 0.0050\n",
      "Epoch 42/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0046 - mse: 0.0030 - val_loss: 0.0066 - val_mse: 0.0051\n",
      "Epoch 43/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0046 - mse: 0.0030 - val_loss: 0.0066 - val_mse: 0.0051\n",
      "Epoch 44/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0045 - mse: 0.0030 - val_loss: 0.0066 - val_mse: 0.0051\n",
      "Epoch 45/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0045 - mse: 0.0030 - val_loss: 0.0065 - val_mse: 0.0050\n",
      "Epoch 46/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0044 - mse: 0.0029 - val_loss: 0.0064 - val_mse: 0.0050\n",
      "Epoch 47/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0044 - mse: 0.0029 - val_loss: 0.0064 - val_mse: 0.0050\n",
      "Epoch 48/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0044 - mse: 0.0029 - val_loss: 0.0063 - val_mse: 0.0049\n",
      "Epoch 49/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0043 - mse: 0.0029 - val_loss: 0.0062 - val_mse: 0.0049\n",
      "Epoch 50/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0043 - mse: 0.0029 - val_loss: 0.0062 - val_mse: 0.0048\n",
      "Epoch 51/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0042 - mse: 0.0029 - val_loss: 0.0061 - val_mse: 0.0048\n",
      "Epoch 52/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0042 - mse: 0.0029 - val_loss: 0.0060 - val_mse: 0.0048\n",
      "Epoch 53/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0042 - mse: 0.0029 - val_loss: 0.0060 - val_mse: 0.0047\n",
      "Epoch 54/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0042 - mse: 0.0029 - val_loss: 0.0059 - val_mse: 0.0047\n",
      "Epoch 55/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0041 - mse: 0.0029 - val_loss: 0.0059 - val_mse: 0.0046\n",
      "Epoch 56/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0041 - mse: 0.0028 - val_loss: 0.0058 - val_mse: 0.0046\n",
      "Epoch 57/70\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0041 - mse: 0.0028 - val_loss: 0.0058 - val_mse: 0.0046\n",
      "Epoch 58/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0041 - mse: 0.0028 - val_loss: 0.0057 - val_mse: 0.0045\n",
      "Epoch 59/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0040 - mse: 0.0028 - val_loss: 0.0056 - val_mse: 0.0045\n",
      "Epoch 60/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0040 - mse: 0.0028 - val_loss: 0.0056 - val_mse: 0.0044\n",
      "Epoch 61/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0040 - mse: 0.0028 - val_loss: 0.0055 - val_mse: 0.0044\n",
      "Epoch 62/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0040 - mse: 0.0028 - val_loss: 0.0054 - val_mse: 0.0043\n",
      "Epoch 63/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0040 - mse: 0.0028 - val_loss: 0.0054 - val_mse: 0.0043\n",
      "Epoch 64/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0040 - mse: 0.0028 - val_loss: 0.0053 - val_mse: 0.0042\n",
      "Epoch 65/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0040 - mse: 0.0028 - val_loss: 0.0052 - val_mse: 0.0041\n",
      "Epoch 66/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0040 - mse: 0.0028 - val_loss: 0.0051 - val_mse: 0.0040\n",
      "Epoch 67/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0040 - mse: 0.0028 - val_loss: 0.0051 - val_mse: 0.0040\n",
      "Epoch 68/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0039 - mse: 0.0028 - val_loss: 0.0050 - val_mse: 0.0039\n",
      "Epoch 69/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0039 - mse: 0.0028 - val_loss: 0.0049 - val_mse: 0.0039\n",
      "Epoch 70/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0039 - mse: 0.0028 - val_loss: 0.0049 - val_mse: 0.0038\n",
      "[ 09:17:09] getting statistics\n",
      "--------------------\n",
      "training window 43654\n",
      "Epoch 1/70\n",
      "101/101 [==============================] - 5s 10ms/step - loss: 0.1434 - mse: 0.1180 - val_loss: 0.0466 - val_mse: 0.0345\n",
      "Epoch 2/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0245 - mse: 0.0167 - val_loss: 0.0392 - val_mse: 0.0338\n",
      "Epoch 3/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0210 - mse: 0.0156 - val_loss: 0.0352 - val_mse: 0.0304\n",
      "Epoch 4/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0190 - mse: 0.0141 - val_loss: 0.0327 - val_mse: 0.0281\n",
      "Epoch 5/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0176 - mse: 0.0130 - val_loss: 0.0309 - val_mse: 0.0263\n",
      "Epoch 6/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0165 - mse: 0.0120 - val_loss: 0.0294 - val_mse: 0.0249\n",
      "Epoch 7/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0156 - mse: 0.0113 - val_loss: 0.0283 - val_mse: 0.0239\n",
      "Epoch 8/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0149 - mse: 0.0106 - val_loss: 0.0275 - val_mse: 0.0231\n",
      "Epoch 9/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0143 - mse: 0.0100 - val_loss: 0.0269 - val_mse: 0.0225\n",
      "Epoch 10/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0137 - mse: 0.0095 - val_loss: 0.0263 - val_mse: 0.0220\n",
      "Epoch 11/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0132 - mse: 0.0091 - val_loss: 0.0259 - val_mse: 0.0216\n",
      "Epoch 12/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0128 - mse: 0.0086 - val_loss: 0.0256 - val_mse: 0.0213\n",
      "Epoch 13/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0124 - mse: 0.0083 - val_loss: 0.0253 - val_mse: 0.0210\n",
      "Epoch 14/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0120 - mse: 0.0079 - val_loss: 0.0250 - val_mse: 0.0208\n",
      "Epoch 15/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0116 - mse: 0.0076 - val_loss: 0.0248 - val_mse: 0.0206\n",
      "Epoch 16/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0113 - mse: 0.0074 - val_loss: 0.0245 - val_mse: 0.0205\n",
      "Epoch 17/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0110 - mse: 0.0071 - val_loss: 0.0243 - val_mse: 0.0203\n",
      "Epoch 18/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0107 - mse: 0.0069 - val_loss: 0.0240 - val_mse: 0.0201\n",
      "Epoch 19/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0104 - mse: 0.0067 - val_loss: 0.0237 - val_mse: 0.0199\n",
      "Epoch 20/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0102 - mse: 0.0065 - val_loss: 0.0233 - val_mse: 0.0195\n",
      "Epoch 21/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0063 - val_loss: 0.0229 - val_mse: 0.0192\n",
      "Epoch 22/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0062 - val_loss: 0.0224 - val_mse: 0.0188\n",
      "Epoch 23/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0094 - mse: 0.0060 - val_loss: 0.0219 - val_mse: 0.0184\n",
      "Epoch 24/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0092 - mse: 0.0059 - val_loss: 0.0214 - val_mse: 0.0181\n",
      "Epoch 25/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0090 - mse: 0.0058 - val_loss: 0.0208 - val_mse: 0.0175\n",
      "Epoch 26/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0057 - val_loss: 0.0202 - val_mse: 0.0170\n",
      "Epoch 27/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0086 - mse: 0.0056 - val_loss: 0.0197 - val_mse: 0.0167\n",
      "Epoch 28/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0084 - mse: 0.0055 - val_loss: 0.0190 - val_mse: 0.0160\n",
      "Epoch 29/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0082 - mse: 0.0054 - val_loss: 0.0184 - val_mse: 0.0156\n",
      "Epoch 30/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0080 - mse: 0.0053 - val_loss: 0.0178 - val_mse: 0.0151\n",
      "Epoch 31/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0078 - mse: 0.0052 - val_loss: 0.0173 - val_mse: 0.0146\n",
      "Epoch 32/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0076 - mse: 0.0051 - val_loss: 0.0168 - val_mse: 0.0142\n",
      "Epoch 33/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0074 - mse: 0.0050 - val_loss: 0.0163 - val_mse: 0.0138\n",
      "Epoch 34/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0049 - val_loss: 0.0158 - val_mse: 0.0134\n",
      "Epoch 35/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0071 - mse: 0.0048 - val_loss: 0.0154 - val_mse: 0.0131\n",
      "Epoch 36/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0070 - mse: 0.0048 - val_loss: 0.0150 - val_mse: 0.0128\n",
      "Epoch 37/70\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0068 - mse: 0.0047 - val_loss: 0.0147 - val_mse: 0.0126\n",
      "Epoch 38/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0067 - mse: 0.0046 - val_loss: 0.0145 - val_mse: 0.0124\n",
      "Epoch 39/70\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0066 - mse: 0.0046 - val_loss: 0.0142 - val_mse: 0.0122\n",
      "Epoch 40/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0065 - mse: 0.0045 - val_loss: 0.0140 - val_mse: 0.0120\n",
      "Epoch 41/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0064 - mse: 0.0045 - val_loss: 0.0138 - val_mse: 0.0119\n",
      "Epoch 42/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0063 - mse: 0.0044 - val_loss: 0.0137 - val_mse: 0.0118\n",
      "Epoch 43/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0062 - mse: 0.0044 - val_loss: 0.0135 - val_mse: 0.0117\n",
      "Epoch 44/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0061 - mse: 0.0043 - val_loss: 0.0134 - val_mse: 0.0116\n",
      "Epoch 45/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0060 - mse: 0.0043 - val_loss: 0.0133 - val_mse: 0.0115\n",
      "Epoch 46/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0059 - mse: 0.0043 - val_loss: 0.0131 - val_mse: 0.0114\n",
      "Epoch 47/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0059 - mse: 0.0042 - val_loss: 0.0131 - val_mse: 0.0114\n",
      "Epoch 48/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0058 - mse: 0.0042 - val_loss: 0.0130 - val_mse: 0.0113\n",
      "Epoch 49/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0057 - mse: 0.0042 - val_loss: 0.0129 - val_mse: 0.0113\n",
      "Epoch 50/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0056 - mse: 0.0041 - val_loss: 0.0128 - val_mse: 0.0113\n",
      "Epoch 51/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0056 - mse: 0.0041 - val_loss: 0.0127 - val_mse: 0.0112\n",
      "Epoch 52/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0055 - mse: 0.0041 - val_loss: 0.0127 - val_mse: 0.0112\n",
      "Epoch 53/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0055 - mse: 0.0041 - val_loss: 0.0126 - val_mse: 0.0111\n",
      "Epoch 54/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0054 - mse: 0.0040 - val_loss: 0.0125 - val_mse: 0.0111\n",
      "Epoch 55/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0054 - mse: 0.0040 - val_loss: 0.0125 - val_mse: 0.0111\n",
      "Epoch 56/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 0.0040 - val_loss: 0.0124 - val_mse: 0.0110\n",
      "Epoch 57/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 0.0040 - val_loss: 0.0123 - val_mse: 0.0110\n",
      "Epoch 58/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 0.0039 - val_loss: 0.0123 - val_mse: 0.0110\n",
      "Epoch 59/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 0.0039 - val_loss: 0.0123 - val_mse: 0.0110\n",
      "Epoch 60/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0051 - mse: 0.0039 - val_loss: 0.0122 - val_mse: 0.0109\n",
      "Epoch 61/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0051 - mse: 0.0039 - val_loss: 0.0122 - val_mse: 0.0109\n",
      "Epoch 62/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0050 - mse: 0.0038 - val_loss: 0.0121 - val_mse: 0.0109\n",
      "Epoch 63/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0050 - mse: 0.0038 - val_loss: 0.0120 - val_mse: 0.0108\n",
      "Epoch 64/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0049 - mse: 0.0038 - val_loss: 0.0120 - val_mse: 0.0108\n",
      "Epoch 65/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0049 - mse: 0.0038 - val_loss: 0.0120 - val_mse: 0.0108\n",
      "Epoch 66/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0049 - mse: 0.0038 - val_loss: 0.0119 - val_mse: 0.0108\n",
      "Epoch 67/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0048 - mse: 0.0037 - val_loss: 0.0119 - val_mse: 0.0107\n",
      "Epoch 68/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0048 - mse: 0.0037 - val_loss: 0.0118 - val_mse: 0.0107\n",
      "Epoch 69/70\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0048 - mse: 0.0037 - val_loss: 0.0118 - val_mse: 0.0107\n",
      "Epoch 70/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0047 - mse: 0.0037 - val_loss: 0.0118 - val_mse: 0.0107\n",
      "[ 09:17:47] getting statistics\n",
      "--------------------\n",
      "training window 45333\n",
      "Epoch 1/70\n",
      "101/101 [==============================] - 4s 8ms/step - loss: 0.1401 - mse: 0.1151 - val_loss: 0.0817 - val_mse: 0.0719\n",
      "Epoch 2/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0272 - mse: 0.0203 - val_loss: 0.0178 - val_mse: 0.0125\n",
      "Epoch 3/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0137 - val_loss: 0.0156 - val_mse: 0.0106\n",
      "Epoch 4/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0172 - mse: 0.0122 - val_loss: 0.0141 - val_mse: 0.0093\n",
      "Epoch 5/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0112 - val_loss: 0.0131 - val_mse: 0.0084\n",
      "Epoch 6/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0105 - val_loss: 0.0124 - val_mse: 0.0077\n",
      "Epoch 7/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0146 - mse: 0.0100 - val_loss: 0.0117 - val_mse: 0.0071\n",
      "Epoch 8/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0141 - mse: 0.0096 - val_loss: 0.0111 - val_mse: 0.0067\n",
      "Epoch 9/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0093 - val_loss: 0.0106 - val_mse: 0.0062\n",
      "Epoch 10/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0090 - val_loss: 0.0101 - val_mse: 0.0058\n",
      "Epoch 11/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0129 - mse: 0.0087 - val_loss: 0.0096 - val_mse: 0.0054\n",
      "Epoch 12/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0126 - mse: 0.0085 - val_loss: 0.0092 - val_mse: 0.0051\n",
      "Epoch 13/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0124 - mse: 0.0083 - val_loss: 0.0088 - val_mse: 0.0048\n",
      "Epoch 14/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0121 - mse: 0.0081 - val_loss: 0.0085 - val_mse: 0.0045\n",
      "Epoch 15/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0119 - mse: 0.0080 - val_loss: 0.0082 - val_mse: 0.0043\n",
      "Epoch 16/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0117 - mse: 0.0078 - val_loss: 0.0079 - val_mse: 0.0040\n",
      "Epoch 17/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0115 - mse: 0.0077 - val_loss: 0.0077 - val_mse: 0.0039\n",
      "Epoch 18/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0113 - mse: 0.0076 - val_loss: 0.0075 - val_mse: 0.0037\n",
      "Epoch 19/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0111 - mse: 0.0074 - val_loss: 0.0072 - val_mse: 0.0036\n",
      "Epoch 20/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0109 - mse: 0.0073 - val_loss: 0.0071 - val_mse: 0.0034\n",
      "Epoch 21/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0108 - mse: 0.0072 - val_loss: 0.0069 - val_mse: 0.0033\n",
      "Epoch 22/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0106 - mse: 0.0072 - val_loss: 0.0068 - val_mse: 0.0033\n",
      "Epoch 23/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0105 - mse: 0.0071 - val_loss: 0.0066 - val_mse: 0.0032\n",
      "Epoch 24/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0104 - mse: 0.0070 - val_loss: 0.0065 - val_mse: 0.0031\n",
      "Epoch 25/70\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0103 - mse: 0.0070 - val_loss: 0.0064 - val_mse: 0.0031\n",
      "Epoch 26/70\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0101 - mse: 0.0069 - val_loss: 0.0063 - val_mse: 0.0030\n",
      "Epoch 27/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0100 - mse: 0.0068 - val_loss: 0.0062 - val_mse: 0.0030\n",
      "Epoch 28/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0099 - mse: 0.0068 - val_loss: 0.0061 - val_mse: 0.0030\n",
      "Epoch 29/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0098 - mse: 0.0067 - val_loss: 0.0060 - val_mse: 0.0029\n",
      "Epoch 30/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0097 - mse: 0.0067 - val_loss: 0.0059 - val_mse: 0.0029\n",
      "Epoch 31/70\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0096 - mse: 0.0067 - val_loss: 0.0059 - val_mse: 0.0029\n",
      "Epoch 32/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0095 - mse: 0.0066 - val_loss: 0.0058 - val_mse: 0.0028\n",
      "Epoch 33/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0094 - mse: 0.0066 - val_loss: 0.0057 - val_mse: 0.0028\n",
      "Epoch 34/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0093 - mse: 0.0065 - val_loss: 0.0056 - val_mse: 0.0028\n",
      "Epoch 35/70\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0092 - mse: 0.0065 - val_loss: 0.0056 - val_mse: 0.0028\n",
      "Epoch 36/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0092 - mse: 0.0065 - val_loss: 0.0054 - val_mse: 0.0027\n",
      "Epoch 37/70\n",
      "101/101 [==============================] - 1s 8ms/step - loss: 0.0091 - mse: 0.0064 - val_loss: 0.0054 - val_mse: 0.0027\n",
      "Epoch 38/70\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 0.0090 - mse: 0.0064 - val_loss: 0.0053 - val_mse: 0.0027\n",
      "Epoch 39/70\n",
      "101/101 [==============================] - 1s 8ms/step - loss: 0.0089 - mse: 0.0064 - val_loss: 0.0052 - val_mse: 0.0027\n",
      "Epoch 40/70\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 0.0088 - mse: 0.0063 - val_loss: 0.0051 - val_mse: 0.0026\n",
      "Epoch 41/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0088 - mse: 0.0063 - val_loss: 0.0051 - val_mse: 0.0026\n",
      "Epoch 42/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0063 - val_loss: 0.0050 - val_mse: 0.0026\n",
      "Epoch 43/70\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0086 - mse: 0.0062 - val_loss: 0.0049 - val_mse: 0.0025\n",
      "Epoch 44/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0085 - mse: 0.0062 - val_loss: 0.0048 - val_mse: 0.0025\n",
      "Epoch 45/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0085 - mse: 0.0062 - val_loss: 0.0048 - val_mse: 0.0025\n",
      "Epoch 46/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0084 - mse: 0.0062 - val_loss: 0.0047 - val_mse: 0.0024\n",
      "Epoch 47/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0083 - mse: 0.0061 - val_loss: 0.0046 - val_mse: 0.0023\n",
      "Epoch 48/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0083 - mse: 0.0061 - val_loss: 0.0045 - val_mse: 0.0024\n",
      "Epoch 49/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0082 - mse: 0.0061 - val_loss: 0.0045 - val_mse: 0.0023\n",
      "Epoch 50/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0081 - mse: 0.0060 - val_loss: 0.0044 - val_mse: 0.0022\n",
      "Epoch 51/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0081 - mse: 0.0060 - val_loss: 0.0043 - val_mse: 0.0022\n",
      "Epoch 52/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0080 - mse: 0.0060 - val_loss: 0.0043 - val_mse: 0.0022\n",
      "Epoch 53/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0079 - mse: 0.0059 - val_loss: 0.0042 - val_mse: 0.0022\n",
      "Epoch 54/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0079 - mse: 0.0059 - val_loss: 0.0041 - val_mse: 0.0021\n",
      "Epoch 55/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0078 - mse: 0.0059 - val_loss: 0.0041 - val_mse: 0.0021\n",
      "Epoch 56/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0078 - mse: 0.0059 - val_loss: 0.0041 - val_mse: 0.0021\n",
      "Epoch 57/70\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0077 - mse: 0.0058 - val_loss: 0.0040 - val_mse: 0.0020\n",
      "Epoch 58/70\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0077 - mse: 0.0058 - val_loss: 0.0039 - val_mse: 0.0020\n",
      "Epoch 59/70\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0076 - mse: 0.0057 - val_loss: 0.0039 - val_mse: 0.0020\n",
      "Epoch 60/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0075 - mse: 0.0057 - val_loss: 0.0038 - val_mse: 0.0019\n",
      "Epoch 61/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0075 - mse: 0.0057 - val_loss: 0.0038 - val_mse: 0.0019\n",
      "Epoch 62/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0075 - mse: 0.0056 - val_loss: 0.0037 - val_mse: 0.0019\n",
      "Epoch 63/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0074 - mse: 0.0056 - val_loss: 0.0037 - val_mse: 0.0019\n",
      "Epoch 64/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0073 - mse: 0.0055 - val_loss: 0.0037 - val_mse: 0.0018\n",
      "Epoch 65/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0073 - mse: 0.0055 - val_loss: 0.0036 - val_mse: 0.0018\n",
      "Epoch 66/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0073 - mse: 0.0055 - val_loss: 0.0037 - val_mse: 0.0019\n",
      "Epoch 67/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0072 - mse: 0.0055 - val_loss: 0.0036 - val_mse: 0.0018\n",
      "Epoch 68/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0072 - mse: 0.0055 - val_loss: 0.0036 - val_mse: 0.0018\n",
      "Epoch 69/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0071 - mse: 0.0054 - val_loss: 0.0035 - val_mse: 0.0017\n",
      "Epoch 70/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0071 - mse: 0.0053 - val_loss: 0.0035 - val_mse: 0.0017\n",
      "[ 09:18:27] getting statistics\n",
      "--------------------\n",
      "training window 47012\n",
      "Epoch 1/70\n",
      "101/101 [==============================] - 4s 7ms/step - loss: 0.1201 - mse: 0.0948 - val_loss: 0.0286 - val_mse: 0.0164\n",
      "Epoch 2/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0192 - val_loss: 0.0190 - val_mse: 0.0134\n",
      "Epoch 3/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0163 - val_loss: 0.0162 - val_mse: 0.0110\n",
      "Epoch 4/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0146 - val_loss: 0.0146 - val_mse: 0.0096\n",
      "Epoch 5/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0186 - mse: 0.0135 - val_loss: 0.0135 - val_mse: 0.0086\n",
      "Epoch 6/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0127 - val_loss: 0.0127 - val_mse: 0.0078\n",
      "Epoch 7/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0120 - val_loss: 0.0120 - val_mse: 0.0072\n",
      "Epoch 8/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0162 - mse: 0.0114 - val_loss: 0.0114 - val_mse: 0.0067\n",
      "Epoch 9/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0109 - val_loss: 0.0109 - val_mse: 0.0062\n",
      "Epoch 10/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0105 - val_loss: 0.0105 - val_mse: 0.0058\n",
      "Epoch 11/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0101 - val_loss: 0.0101 - val_mse: 0.0055\n",
      "Epoch 12/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0098 - val_loss: 0.0097 - val_mse: 0.0052\n",
      "Epoch 13/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0095 - val_loss: 0.0094 - val_mse: 0.0049\n",
      "Epoch 14/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0093 - val_loss: 0.0091 - val_mse: 0.0047\n",
      "Epoch 15/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0135 - mse: 0.0091 - val_loss: 0.0088 - val_mse: 0.0044\n",
      "Epoch 16/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0132 - mse: 0.0089 - val_loss: 0.0085 - val_mse: 0.0042\n",
      "Epoch 17/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0129 - mse: 0.0087 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 18/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0086 - val_loss: 0.0080 - val_mse: 0.0039\n",
      "Epoch 19/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0125 - mse: 0.0084 - val_loss: 0.0077 - val_mse: 0.0037\n",
      "Epoch 20/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0083 - val_loss: 0.0075 - val_mse: 0.0036\n",
      "Epoch 21/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0082 - val_loss: 0.0073 - val_mse: 0.0035\n",
      "Epoch 22/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0119 - mse: 0.0080 - val_loss: 0.0071 - val_mse: 0.0033\n",
      "Epoch 23/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0079 - val_loss: 0.0070 - val_mse: 0.0032\n",
      "Epoch 24/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0115 - mse: 0.0078 - val_loss: 0.0068 - val_mse: 0.0031\n",
      "Epoch 25/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0113 - mse: 0.0077 - val_loss: 0.0066 - val_mse: 0.0030\n",
      "Epoch 26/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0112 - mse: 0.0076 - val_loss: 0.0065 - val_mse: 0.0030\n",
      "Epoch 27/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0110 - mse: 0.0075 - val_loss: 0.0063 - val_mse: 0.0029\n",
      "Epoch 28/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0108 - mse: 0.0074 - val_loss: 0.0062 - val_mse: 0.0028\n",
      "Epoch 29/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0107 - mse: 0.0073 - val_loss: 0.0061 - val_mse: 0.0028\n",
      "Epoch 30/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0072 - val_loss: 0.0060 - val_mse: 0.0027\n",
      "Epoch 31/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0071 - val_loss: 0.0059 - val_mse: 0.0027\n",
      "Epoch 32/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0102 - mse: 0.0070 - val_loss: 0.0058 - val_mse: 0.0026\n",
      "Epoch 33/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0101 - mse: 0.0069 - val_loss: 0.0057 - val_mse: 0.0026\n",
      "Epoch 34/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0068 - val_loss: 0.0056 - val_mse: 0.0026\n",
      "Epoch 35/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0067 - val_loss: 0.0055 - val_mse: 0.0025\n",
      "Epoch 36/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0067 - val_loss: 0.0055 - val_mse: 0.0025\n",
      "Epoch 37/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0096 - mse: 0.0066 - val_loss: 0.0054 - val_mse: 0.0025\n",
      "Epoch 38/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0095 - mse: 0.0065 - val_loss: 0.0054 - val_mse: 0.0025\n",
      "Epoch 39/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0065 - val_loss: 0.0053 - val_mse: 0.0025\n",
      "Epoch 40/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0093 - mse: 0.0064 - val_loss: 0.0053 - val_mse: 0.0025\n",
      "Epoch 41/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0064 - val_loss: 0.0052 - val_mse: 0.0024\n",
      "Epoch 42/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0092 - mse: 0.0064 - val_loss: 0.0052 - val_mse: 0.0024\n",
      "Epoch 43/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0091 - mse: 0.0064 - val_loss: 0.0052 - val_mse: 0.0025\n",
      "Epoch 44/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0091 - mse: 0.0063 - val_loss: 0.0051 - val_mse: 0.0025\n",
      "Epoch 45/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0063 - val_loss: 0.0051 - val_mse: 0.0025\n",
      "Epoch 46/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0063 - val_loss: 0.0051 - val_mse: 0.0025\n",
      "Epoch 47/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0063 - val_loss: 0.0051 - val_mse: 0.0025\n",
      "Epoch 48/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0062 - val_loss: 0.0050 - val_mse: 0.0025\n",
      "Epoch 49/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0062 - val_loss: 0.0050 - val_mse: 0.0025\n",
      "Epoch 50/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0087 - mse: 0.0062 - val_loss: 0.0050 - val_mse: 0.0025\n",
      "Epoch 51/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0086 - mse: 0.0062 - val_loss: 0.0049 - val_mse: 0.0025\n",
      "Epoch 52/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0086 - mse: 0.0062 - val_loss: 0.0049 - val_mse: 0.0025\n",
      "Epoch 53/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0061 - val_loss: 0.0049 - val_mse: 0.0025\n",
      "Epoch 54/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0061 - val_loss: 0.0048 - val_mse: 0.0025\n",
      "Epoch 55/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0084 - mse: 0.0061 - val_loss: 0.0048 - val_mse: 0.0025\n",
      "Epoch 56/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0060 - val_loss: 0.0047 - val_mse: 0.0025\n",
      "Epoch 57/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0060 - val_loss: 0.0047 - val_mse: 0.0025\n",
      "Epoch 58/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0060 - val_loss: 0.0047 - val_mse: 0.0025\n",
      "Epoch 59/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0060 - val_loss: 0.0046 - val_mse: 0.0025\n",
      "Epoch 60/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0059 - val_loss: 0.0046 - val_mse: 0.0025\n",
      "Epoch 61/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0080 - mse: 0.0059 - val_loss: 0.0046 - val_mse: 0.0025\n",
      "Epoch 62/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0059 - val_loss: 0.0046 - val_mse: 0.0025\n",
      "Epoch 63/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0059 - val_loss: 0.0045 - val_mse: 0.0025\n",
      "Epoch 64/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0059 - val_loss: 0.0045 - val_mse: 0.0025\n",
      "Epoch 65/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0058 - val_loss: 0.0045 - val_mse: 0.0025\n",
      "Epoch 66/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0058 - val_loss: 0.0045 - val_mse: 0.0025\n",
      "Epoch 67/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0077 - mse: 0.0058 - val_loss: 0.0044 - val_mse: 0.0025\n",
      "Epoch 68/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0077 - mse: 0.0058 - val_loss: 0.0044 - val_mse: 0.0025\n",
      "Epoch 69/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0058 - val_loss: 0.0044 - val_mse: 0.0025\n",
      "Epoch 70/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0076 - mse: 0.0057 - val_loss: 0.0044 - val_mse: 0.0025\n",
      "[ 09:18:56] getting statistics\n",
      "--------------------\n",
      "training window 48691\n",
      "Epoch 1/70\n",
      "101/101 [==============================] - 3s 7ms/step - loss: 0.1136 - mse: 0.0885 - val_loss: 0.0332 - val_mse: 0.0215\n",
      "Epoch 2/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0165 - val_loss: 0.0216 - val_mse: 0.0165\n",
      "Epoch 3/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0136 - val_loss: 0.0195 - val_mse: 0.0147\n",
      "Epoch 4/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0122 - val_loss: 0.0182 - val_mse: 0.0134\n",
      "Epoch 5/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0112 - val_loss: 0.0172 - val_mse: 0.0125\n",
      "Epoch 6/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0104 - val_loss: 0.0163 - val_mse: 0.0117\n",
      "Epoch 7/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0097 - val_loss: 0.0157 - val_mse: 0.0111\n",
      "Epoch 8/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0090 - val_loss: 0.0151 - val_mse: 0.0105\n",
      "Epoch 9/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0085 - val_loss: 0.0146 - val_mse: 0.0101\n",
      "Epoch 10/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0080 - val_loss: 0.0142 - val_mse: 0.0097\n",
      "Epoch 11/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0121 - mse: 0.0076 - val_loss: 0.0138 - val_mse: 0.0094\n",
      "Epoch 12/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0073 - val_loss: 0.0135 - val_mse: 0.0092\n",
      "Epoch 13/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0114 - mse: 0.0070 - val_loss: 0.0133 - val_mse: 0.0090\n",
      "Epoch 14/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0111 - mse: 0.0068 - val_loss: 0.0130 - val_mse: 0.0088\n",
      "Epoch 15/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0108 - mse: 0.0066 - val_loss: 0.0128 - val_mse: 0.0086\n",
      "Epoch 16/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0106 - mse: 0.0064 - val_loss: 0.0126 - val_mse: 0.0085\n",
      "Epoch 17/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0104 - mse: 0.0063 - val_loss: 0.0125 - val_mse: 0.0084\n",
      "Epoch 18/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0102 - mse: 0.0062 - val_loss: 0.0123 - val_mse: 0.0083\n",
      "Epoch 19/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0060 - val_loss: 0.0123 - val_mse: 0.0084\n",
      "Epoch 20/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0060 - val_loss: 0.0120 - val_mse: 0.0082\n",
      "Epoch 21/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0096 - mse: 0.0058 - val_loss: 0.0119 - val_mse: 0.0082\n",
      "Epoch 22/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0057 - val_loss: 0.0117 - val_mse: 0.0081\n",
      "Epoch 23/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0092 - mse: 0.0056 - val_loss: 0.0116 - val_mse: 0.0081\n",
      "Epoch 24/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0090 - mse: 0.0055 - val_loss: 0.0115 - val_mse: 0.0081\n",
      "Epoch 25/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0055 - val_loss: 0.0114 - val_mse: 0.0081\n",
      "Epoch 26/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0086 - mse: 0.0054 - val_loss: 0.0113 - val_mse: 0.0081\n",
      "Epoch 27/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0085 - mse: 0.0053 - val_loss: 0.0112 - val_mse: 0.0081\n",
      "Epoch 28/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0053 - val_loss: 0.0112 - val_mse: 0.0081\n",
      "Epoch 29/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0052 - val_loss: 0.0111 - val_mse: 0.0081\n",
      "Epoch 30/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0081 - mse: 0.0051 - val_loss: 0.0110 - val_mse: 0.0081\n",
      "Epoch 31/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0079 - mse: 0.0051 - val_loss: 0.0110 - val_mse: 0.0081\n",
      "Epoch 32/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0050 - val_loss: 0.0109 - val_mse: 0.0081\n",
      "Epoch 33/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0050 - val_loss: 0.0108 - val_mse: 0.0081\n",
      "Epoch 34/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0049 - val_loss: 0.0108 - val_mse: 0.0081\n",
      "Epoch 35/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0048 - val_loss: 0.0107 - val_mse: 0.0081\n",
      "Epoch 36/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0048 - val_loss: 0.0106 - val_mse: 0.0080\n",
      "Epoch 37/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0072 - mse: 0.0047 - val_loss: 0.0105 - val_mse: 0.0080\n",
      "Epoch 38/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0071 - mse: 0.0047 - val_loss: 0.0104 - val_mse: 0.0080\n",
      "Epoch 39/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0070 - mse: 0.0046 - val_loss: 0.0104 - val_mse: 0.0080\n",
      "Epoch 40/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0069 - mse: 0.0046 - val_loss: 0.0103 - val_mse: 0.0079\n",
      "Epoch 41/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0045 - val_loss: 0.0102 - val_mse: 0.0079\n",
      "Epoch 42/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 0.0044 - val_loss: 0.0101 - val_mse: 0.0078\n",
      "Epoch 43/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0066 - mse: 0.0044 - val_loss: 0.0100 - val_mse: 0.0078\n",
      "Epoch 44/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0065 - mse: 0.0044 - val_loss: 0.0100 - val_mse: 0.0078\n",
      "Epoch 45/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0064 - mse: 0.0043 - val_loss: 0.0099 - val_mse: 0.0077\n",
      "Epoch 46/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0063 - mse: 0.0043 - val_loss: 0.0098 - val_mse: 0.0077\n",
      "Epoch 47/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0063 - mse: 0.0042 - val_loss: 0.0097 - val_mse: 0.0077\n",
      "Epoch 48/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0062 - mse: 0.0042 - val_loss: 0.0096 - val_mse: 0.0076\n",
      "Epoch 49/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0061 - mse: 0.0041 - val_loss: 0.0096 - val_mse: 0.0076\n",
      "Epoch 50/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0060 - mse: 0.0041 - val_loss: 0.0095 - val_mse: 0.0075\n",
      "Epoch 51/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0060 - mse: 0.0041 - val_loss: 0.0094 - val_mse: 0.0075\n",
      "Epoch 52/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0059 - mse: 0.0040 - val_loss: 0.0093 - val_mse: 0.0074\n",
      "Epoch 53/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0058 - mse: 0.0040 - val_loss: 0.0093 - val_mse: 0.0074\n",
      "Epoch 54/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0058 - mse: 0.0040 - val_loss: 0.0092 - val_mse: 0.0074\n",
      "Epoch 55/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0057 - mse: 0.0039 - val_loss: 0.0091 - val_mse: 0.0073\n",
      "Epoch 56/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0057 - mse: 0.0039 - val_loss: 0.0091 - val_mse: 0.0073\n",
      "Epoch 57/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0056 - mse: 0.0039 - val_loss: 0.0090 - val_mse: 0.0072\n",
      "Epoch 58/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0056 - mse: 0.0038 - val_loss: 0.0089 - val_mse: 0.0072\n",
      "Epoch 59/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 0.0038 - val_loss: 0.0089 - val_mse: 0.0072\n",
      "Epoch 60/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0055 - mse: 0.0038 - val_loss: 0.0088 - val_mse: 0.0071\n",
      "Epoch 61/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 0.0038 - val_loss: 0.0088 - val_mse: 0.0071\n",
      "Epoch 62/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 0.0038 - val_loss: 0.0087 - val_mse: 0.0071\n",
      "Epoch 63/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 0.0037 - val_loss: 0.0087 - val_mse: 0.0071\n",
      "Epoch 64/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0053 - mse: 0.0037 - val_loss: 0.0087 - val_mse: 0.0071\n",
      "Epoch 65/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 0.0037 - val_loss: 0.0086 - val_mse: 0.0071\n",
      "Epoch 66/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0052 - mse: 0.0037 - val_loss: 0.0086 - val_mse: 0.0070\n",
      "Epoch 67/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0052 - mse: 0.0037 - val_loss: 0.0086 - val_mse: 0.0070\n",
      "Epoch 68/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 0.0037 - val_loss: 0.0086 - val_mse: 0.0070\n",
      "Epoch 69/70\n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 0.0037 - val_loss: 0.0085 - val_mse: 0.0070\n",
      "Epoch 70/70\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.0051 - mse: 0.0037 - val_loss: 0.0085 - val_mse: 0.0070\n",
      "[ 09:19:24] getting statistics\n"
     ]
    }
   ],
   "source": [
    "meas = sliding_window_LSTM(data,30,0.75)\n",
    "measures = meas\n",
    "rmse = round(statistics.mean(measures['rmse']),3)\n",
    "mape = round(statistics.mean(measures['mape']),3)\n",
    "smape = round(statistics.mean(measures['smape']),3)\n",
    "mae = round(statistics.mean(measures['mae']),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd080073-8eee-46a3-9490-60386b54f8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.594\n",
      "129.681\n",
      "24.387\n",
      "0.388\n"
     ]
    }
   ],
   "source": [
    "print (rmse)\n",
    "print (mape)\n",
    "print (smape)\n",
    "print (mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "679c5b59-6298-45c1-aeef-bf088a255b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame) \n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f3e62c0-4440-4bfe-b2ff-8bc40cfad95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (2,3,4,5,6,7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.216</td>\n",
       "      <td>0.418</td>\n",
       "      <td>234.84</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2.720</td>\n",
       "      <td>0.000</td>\n",
       "      <td>235.06</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>3.452</td>\n",
       "      <td>0.000</td>\n",
       "      <td>235.20</td>\n",
       "      <td>15.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>4.298</td>\n",
       "      <td>0.000</td>\n",
       "      <td>232.39</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>3.262</td>\n",
       "      <td>0.052</td>\n",
       "      <td>232.64</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Global_active_power  Global_reactive_power  Voltage  Global_intensity  \\\n",
       "0                  4.216                  0.418   234.84              18.4   \n",
       "30                 2.720                  0.000   235.06              11.6   \n",
       "60                 3.452                  0.000   235.20              15.2   \n",
       "90                 4.298                  0.000   232.39              18.4   \n",
       "120                3.262                  0.052   232.64              14.0   \n",
       "\n",
       "     Sub_metering_1  Sub_metering_2  Sub_metering_3  \n",
       "0               0.0             1.0            17.0  \n",
       "30              0.0             0.0            17.0  \n",
       "60              0.0             1.0            17.0  \n",
       "90              0.0             1.0            16.0  \n",
       "120             0.0             0.0            17.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('household_power_consumption.csv', sep = \";\")\n",
    "data = data.drop(labels=['Time','Date'], axis=1)\n",
    "data = data.loc[0: : 30] # 30 minutes\n",
    "data.dropna(inplace = True)\n",
    "data = clean_dataset(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8db0278-9575-4570-8e03-59e56c42bc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_LSTM(data,n_windows,train_size): \n",
    "    result = {\n",
    "         \"window\": [],\n",
    "         \"rmse\": [],\n",
    "         \"mape\": [],\n",
    "         \"smape\": [],\n",
    "         \"mae\": []\n",
    "    }\n",
    "\n",
    "    order = 1\n",
    "    tam = len(data)\n",
    "    n_windows = 30\n",
    "    windows_length = math.floor(tam / n_windows)\n",
    "    for ct, ttrain, ttest in Util.sliding_window(data, windows_length, 0.75, inc=1):\n",
    "        if len(ttest) > 0:\n",
    "        \n",
    "            X_train = ttrain.loc[:,'Global_reactive_power':'Sub_metering_3']\n",
    "            X_test = ttest.loc[:,'Global_reactive_power':'Sub_metering_3']\n",
    "            y_train = ttrain['Global_active_power']\n",
    "            y_test = ttest['Global_active_power']\n",
    "            \n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.fit_transform(X_test)\n",
    "            y_train = scalertrain.fit_transform(y_train.values.reshape(-1,1))\n",
    "            y_test = scalertest.fit_transform(y_test.values.reshape(-1,1))\n",
    "            \n",
    "            X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "            X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "            y_train = y_train.reshape((y_train.shape[0], 1))\n",
    "            y_test = y_test.reshape((y_test.shape[0], 1))\n",
    "            \n",
    "        \n",
    "            print('-' * 20)\n",
    "            print(f'training window {(ct)}')\n",
    "            \n",
    "            # design network\n",
    "            from keras.callbacks import EarlyStopping\n",
    "            model = Sequential()\n",
    "            model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True, activity_regularizer=regularizers.l2(10e-5),\n",
    "               activation='relu', kernel_regularizer=regularizers.l1(10e-5), recurrent_regularizer = regularizers.l2(10e-5)))\n",
    "            model.add(LSTM(30, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True, activation='relu'))\n",
    "            model.add(LSTM(10, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False, activation='relu'))\n",
    "#model.add(LSTM(5, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=False, activation='relu'))\n",
    "#model.add(LSTM(1, input_shape=(train_X.shape[1], train_X.shape[2]))) \n",
    "#model.add(Dropout(0.2))\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "            model.compile(loss='mse', optimizer='adam',metrics=['mse'])\n",
    "\n",
    "            epochs = 50\n",
    "            batch_size=10\n",
    "            import matplotlib.pyplot as plt\n",
    "            history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_split=0.2,  shuffle=False)\n",
    "            yhat = model.predict(X_test)\n",
    "            \n",
    "            y_test = scalertest.inverse_transform(y_test)\n",
    "            forecast = scalertest.inverse_transform(yhat)\n",
    "            \n",
    "            \n",
    "            print(\"[{0: %H:%M:%S}]\".format(datetime.datetime.now()) + f\" getting statistics\")\n",
    "            rmse = Measures.rmse(y_test,forecast)\n",
    "            mape = Measures.mape(y_test,forecast)\n",
    "            smape = Measures.smape(y_test,forecast)\n",
    "        \n",
    "            forecast = pd.DataFrame(forecast)\n",
    "            forecast.fillna(forecast.mean(),inplace=True)\n",
    "            forecast = np.array(forecast).reshape(-1)\n",
    "            mae = mean_absolute_error(y_test, forecast)\n",
    "\n",
    "        \n",
    "            result[\"rmse\"].append(rmse)\n",
    "            result[\"mape\"].append(mape)\n",
    "            result[\"smape\"].append(smape)\n",
    "            result[\"mae\"].append(mae)\n",
    "            result[\"window\"].append(ct)\n",
    "        \n",
    "            \n",
    "    measures = pd.DataFrame(result)\n",
    "    return measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6f759b0-3b65-44cb-9086-ea0e1496e8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 0s 3ms/step - loss: 8.2843e-04 - mse: 2.6373e-04 - val_loss: 6.8980e-04 - val_mse: 1.5229e-04\n",
      "Epoch 44/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.9317e-04 - mse: 2.4288e-04 - val_loss: 6.6760e-04 - val_mse: 1.4377e-04\n",
      "Epoch 45/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.6081e-04 - mse: 2.2526e-04 - val_loss: 6.4663e-04 - val_mse: 1.3610e-04\n",
      "Epoch 46/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.3170e-04 - mse: 2.1096e-04 - val_loss: 6.2784e-04 - val_mse: 1.3035e-04\n",
      "Epoch 47/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.0452e-04 - mse: 1.9772e-04 - val_loss: 6.1256e-04 - val_mse: 1.2685e-04\n",
      "Epoch 48/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 6.7933e-04 - mse: 1.8549e-04 - val_loss: 6.0004e-04 - val_mse: 1.2418e-04\n",
      "Epoch 49/50\n",
      "137/137 [==============================] - 0s 4ms/step - loss: 6.6195e-04 - mse: 1.7978e-04 - val_loss: 5.8494e-04 - val_mse: 1.1980e-04\n",
      "Epoch 50/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.4538e-04 - mse: 1.7512e-04 - val_loss: 5.6815e-04 - val_mse: 1.1454e-04\n",
      "[ 09:27:10] getting statistics\n",
      "--------------------\n",
      "training window 31864\n",
      "Epoch 1/50\n",
      "137/137 [==============================] - 4s 5ms/step - loss: 0.1191 - mse: 0.1123 - val_loss: 0.0150 - val_mse: 0.0121\n",
      "Epoch 2/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0108 - mse: 0.0082 - val_loss: 0.0076 - val_mse: 0.0052\n",
      "Epoch 3/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0049 - val_loss: 0.0058 - val_mse: 0.0034\n",
      "Epoch 4/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0060 - mse: 0.0036 - val_loss: 0.0052 - val_mse: 0.0028\n",
      "Epoch 5/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0054 - mse: 0.0029 - val_loss: 0.0049 - val_mse: 0.0025\n",
      "Epoch 6/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0049 - mse: 0.0025 - val_loss: 0.0046 - val_mse: 0.0023\n",
      "Epoch 7/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0045 - mse: 0.0022 - val_loss: 0.0043 - val_mse: 0.0020\n",
      "Epoch 8/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0041 - mse: 0.0019 - val_loss: 0.0040 - val_mse: 0.0018\n",
      "Epoch 9/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0037 - mse: 0.0017 - val_loss: 0.0036 - val_mse: 0.0016\n",
      "Epoch 10/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0034 - mse: 0.0014 - val_loss: 0.0033 - val_mse: 0.0014\n",
      "Epoch 11/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0030 - mse: 0.0012 - val_loss: 0.0029 - val_mse: 0.0012\n",
      "Epoch 12/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0027 - mse: 0.0010 - val_loss: 0.0026 - val_mse: 0.0011\n",
      "Epoch 13/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0024 - mse: 8.8490e-04 - val_loss: 0.0023 - val_mse: 9.1236e-04\n",
      "Epoch 14/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0022 - mse: 7.7962e-04 - val_loss: 0.0021 - val_mse: 7.7675e-04\n",
      "Epoch 15/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0020 - mse: 7.1682e-04 - val_loss: 0.0019 - val_mse: 6.6633e-04\n",
      "Epoch 16/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 6.8511e-04 - val_loss: 0.0017 - val_mse: 5.5797e-04\n",
      "Epoch 17/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0018 - mse: 6.6903e-04 - val_loss: 0.0015 - val_mse: 4.6041e-04\n",
      "Epoch 18/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0017 - mse: 6.5778e-04 - val_loss: 0.0014 - val_mse: 3.9282e-04\n",
      "Epoch 19/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0016 - mse: 6.4956e-04 - val_loss: 0.0013 - val_mse: 3.5333e-04\n",
      "Epoch 20/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0015 - mse: 6.4514e-04 - val_loss: 0.0012 - val_mse: 3.3159e-04\n",
      "Epoch 21/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0015 - mse: 6.4407e-04 - val_loss: 0.0011 - val_mse: 3.2185e-04\n",
      "Epoch 22/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 6.4438e-04 - val_loss: 0.0010 - val_mse: 3.2078e-04\n",
      "Epoch 23/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 6.4435e-04 - val_loss: 9.8447e-04 - val_mse: 3.2694e-04\n",
      "Epoch 24/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 6.4301e-04 - val_loss: 9.4322e-04 - val_mse: 3.3589e-04\n",
      "Epoch 25/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 6.4048e-04 - val_loss: 9.0632e-04 - val_mse: 3.4120e-04\n",
      "Epoch 26/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 6.3553e-04 - val_loss: 8.7541e-04 - val_mse: 3.4764e-04\n",
      "Epoch 27/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 6.2361e-04 - val_loss: 8.2997e-04 - val_mse: 3.3271e-04\n",
      "Epoch 28/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 5.9500e-04 - val_loss: 7.8298e-04 - val_mse: 3.0915e-04\n",
      "Epoch 29/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0010 - mse: 5.4864e-04 - val_loss: 7.2246e-04 - val_mse: 2.6381e-04\n",
      "Epoch 30/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 9.6939e-04 - mse: 5.1105e-04 - val_loss: 6.6383e-04 - val_mse: 2.2004e-04\n",
      "Epoch 31/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 9.2999e-04 - mse: 4.8847e-04 - val_loss: 6.1377e-04 - val_mse: 1.8850e-04\n",
      "Epoch 32/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.9612e-04 - mse: 4.7135e-04 - val_loss: 5.7501e-04 - val_mse: 1.6893e-04\n",
      "Epoch 33/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.6491e-04 - mse: 4.5763e-04 - val_loss: 5.4506e-04 - val_mse: 1.5568e-04\n",
      "Epoch 34/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.3503e-04 - mse: 4.4530e-04 - val_loss: 5.1833e-04 - val_mse: 1.4533e-04\n",
      "Epoch 35/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.0812e-04 - mse: 4.3356e-04 - val_loss: 4.9759e-04 - val_mse: 1.3924e-04\n",
      "Epoch 36/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.8158e-04 - mse: 4.2298e-04 - val_loss: 4.7720e-04 - val_mse: 1.3492e-04\n",
      "Epoch 37/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.5562e-04 - mse: 4.1308e-04 - val_loss: 4.5615e-04 - val_mse: 1.2921e-04\n",
      "Epoch 38/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.3026e-04 - mse: 4.0363e-04 - val_loss: 4.3554e-04 - val_mse: 1.2324e-04\n",
      "Epoch 39/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.0607e-04 - mse: 3.9500e-04 - val_loss: 4.1614e-04 - val_mse: 1.1790e-04\n",
      "Epoch 40/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.8376e-04 - mse: 3.8490e-04 - val_loss: 3.9863e-04 - val_mse: 1.1032e-04\n",
      "Epoch 41/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.6448e-04 - mse: 3.7490e-04 - val_loss: 3.8531e-04 - val_mse: 1.0532e-04\n",
      "Epoch 42/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.4671e-04 - mse: 3.6569e-04 - val_loss: 3.7210e-04 - val_mse: 9.9782e-05\n",
      "Epoch 43/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.3009e-04 - mse: 3.5745e-04 - val_loss: 3.5999e-04 - val_mse: 9.5864e-05\n",
      "Epoch 44/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.1416e-04 - mse: 3.4968e-04 - val_loss: 3.4912e-04 - val_mse: 9.2947e-05\n",
      "Epoch 45/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.0137e-04 - mse: 3.4357e-04 - val_loss: 3.4193e-04 - val_mse: 9.0532e-05\n",
      "Epoch 46/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.9134e-04 - mse: 3.3812e-04 - val_loss: 3.3507e-04 - val_mse: 8.8213e-05\n",
      "Epoch 47/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.7833e-04 - mse: 3.2996e-04 - val_loss: 3.2748e-04 - val_mse: 8.5680e-05\n",
      "Epoch 48/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.6691e-04 - mse: 3.2332e-04 - val_loss: 3.2207e-04 - val_mse: 8.4630e-05\n",
      "Epoch 49/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.5574e-04 - mse: 3.1731e-04 - val_loss: 3.1482e-04 - val_mse: 8.3101e-05\n",
      "Epoch 50/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.4432e-04 - mse: 3.1103e-04 - val_loss: 3.0989e-04 - val_mse: 8.2317e-05\n",
      "[ 09:27:32] getting statistics\n",
      "--------------------\n",
      "training window 34140\n",
      "Epoch 1/50\n",
      "137/137 [==============================] - 3s 5ms/step - loss: 0.1184 - mse: 0.1121 - val_loss: 0.0399 - val_mse: 0.0377\n",
      "Epoch 2/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0162 - val_loss: 0.0101 - val_mse: 0.0075\n",
      "Epoch 3/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0077 - val_loss: 0.0071 - val_mse: 0.0045\n",
      "Epoch 4/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0057 - val_loss: 0.0059 - val_mse: 0.0034\n",
      "Epoch 5/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0069 - mse: 0.0046 - val_loss: 0.0052 - val_mse: 0.0028\n",
      "Epoch 6/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0059 - mse: 0.0037 - val_loss: 0.0048 - val_mse: 0.0026\n",
      "Epoch 7/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0051 - mse: 0.0030 - val_loss: 0.0045 - val_mse: 0.0025\n",
      "Epoch 8/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0042 - mse: 0.0024 - val_loss: 0.0043 - val_mse: 0.0024\n",
      "Epoch 9/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0036 - mse: 0.0019 - val_loss: 0.0040 - val_mse: 0.0022\n",
      "Epoch 10/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0031 - mse: 0.0015 - val_loss: 0.0037 - val_mse: 0.0021\n",
      "Epoch 11/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0028 - mse: 0.0012 - val_loss: 0.0034 - val_mse: 0.0019\n",
      "Epoch 12/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0025 - mse: 0.0010 - val_loss: 0.0031 - val_mse: 0.0017\n",
      "Epoch 13/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0022 - mse: 9.0313e-04 - val_loss: 0.0029 - val_mse: 0.0016\n",
      "Epoch 14/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 8.0977e-04 - val_loss: 0.0027 - val_mse: 0.0015\n",
      "Epoch 15/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 7.5064e-04 - val_loss: 0.0026 - val_mse: 0.0014\n",
      "Epoch 16/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0018 - mse: 7.1336e-04 - val_loss: 0.0024 - val_mse: 0.0013\n",
      "Epoch 17/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0017 - mse: 6.8810e-04 - val_loss: 0.0024 - val_mse: 0.0013\n",
      "Epoch 18/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0016 - mse: 6.6514e-04 - val_loss: 0.0023 - val_mse: 0.0013\n",
      "Epoch 19/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0015 - mse: 6.1512e-04 - val_loss: 0.0023 - val_mse: 0.0014\n",
      "Epoch 20/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 5.6369e-04 - val_loss: 0.0022 - val_mse: 0.0013\n",
      "Epoch 21/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 5.3200e-04 - val_loss: 0.0021 - val_mse: 0.0013\n",
      "Epoch 22/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 5.0758e-04 - val_loss: 0.0020 - val_mse: 0.0013\n",
      "Epoch 23/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 4.8139e-04 - val_loss: 0.0020 - val_mse: 0.0012\n",
      "Epoch 24/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 4.5490e-04 - val_loss: 0.0019 - val_mse: 0.0012\n",
      "Epoch 25/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0010 - mse: 4.2561e-04 - val_loss: 0.0018 - val_mse: 0.0012\n",
      "Epoch 26/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 9.6723e-04 - mse: 3.9223e-04 - val_loss: 0.0017 - val_mse: 0.0011\n",
      "Epoch 27/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.8491e-04 - mse: 3.5433e-04 - val_loss: 0.0015 - val_mse: 9.8751e-04\n",
      "Epoch 28/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.0618e-04 - mse: 3.1487e-04 - val_loss: 0.0013 - val_mse: 8.4862e-04\n",
      "Epoch 29/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.3833e-04 - mse: 2.7679e-04 - val_loss: 0.0012 - val_mse: 7.1913e-04\n",
      "Epoch 30/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.7748e-04 - mse: 2.4456e-04 - val_loss: 0.0010 - val_mse: 5.8494e-04\n",
      "Epoch 31/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.2719e-04 - mse: 2.1786e-04 - val_loss: 8.5740e-04 - val_mse: 4.5181e-04\n",
      "Epoch 32/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.8969e-04 - mse: 1.9638e-04 - val_loss: 7.4036e-04 - val_mse: 3.5000e-04\n",
      "Epoch 33/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.5914e-04 - mse: 1.7972e-04 - val_loss: 6.4908e-04 - val_mse: 2.7379e-04\n",
      "Epoch 34/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.3440e-04 - mse: 1.6555e-04 - val_loss: 5.8405e-04 - val_mse: 2.1886e-04\n",
      "Epoch 35/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.1459e-04 - mse: 1.5360e-04 - val_loss: 5.4006e-04 - val_mse: 1.8207e-04\n",
      "Epoch 36/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.9885e-04 - mse: 1.4388e-04 - val_loss: 5.0861e-04 - val_mse: 1.5760e-04\n",
      "Epoch 37/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.8889e-04 - mse: 1.3857e-04 - val_loss: 4.8442e-04 - val_mse: 1.3959e-04\n",
      "Epoch 38/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.7998e-04 - mse: 1.3350e-04 - val_loss: 4.6698e-04 - val_mse: 1.2681e-04\n",
      "Epoch 39/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.7019e-04 - mse: 1.2723e-04 - val_loss: 4.5382e-04 - val_mse: 1.1729e-04\n",
      "Epoch 40/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.6374e-04 - mse: 1.2417e-04 - val_loss: 4.4489e-04 - val_mse: 1.1151e-04\n",
      "Epoch 41/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.6001e-04 - mse: 1.2393e-04 - val_loss: 4.3908e-04 - val_mse: 1.0881e-04\n",
      "Epoch 42/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.5554e-04 - mse: 1.2309e-04 - val_loss: 4.3632e-04 - val_mse: 1.0839e-04\n",
      "Epoch 43/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.5203e-04 - mse: 1.2269e-04 - val_loss: 4.3321e-04 - val_mse: 1.0826e-04\n",
      "Epoch 44/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.4996e-04 - mse: 1.2403e-04 - val_loss: 4.2910e-04 - val_mse: 1.0770e-04\n",
      "Epoch 45/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.4695e-04 - mse: 1.2454e-04 - val_loss: 4.2534e-04 - val_mse: 1.0772e-04\n",
      "Epoch 46/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.4338e-04 - mse: 1.2477e-04 - val_loss: 4.2221e-04 - val_mse: 1.0725e-04\n",
      "Epoch 47/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.3869e-04 - mse: 1.2373e-04 - val_loss: 4.1866e-04 - val_mse: 1.0736e-04\n",
      "Epoch 48/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.3571e-04 - mse: 1.2399e-04 - val_loss: 4.1571e-04 - val_mse: 1.0708e-04\n",
      "Epoch 49/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.2914e-04 - mse: 1.2111e-04 - val_loss: 4.1103e-04 - val_mse: 1.0621e-04\n",
      "Epoch 50/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.2634e-04 - mse: 1.2169e-04 - val_loss: 4.1408e-04 - val_mse: 1.1166e-04\n",
      "[ 09:27:55] getting statistics\n",
      "--------------------\n",
      "training window 36416\n",
      "Epoch 1/50\n",
      "137/137 [==============================] - 3s 5ms/step - loss: 0.1108 - mse: 0.1042 - val_loss: 0.0337 - val_mse: 0.0313\n",
      "Epoch 2/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0201 - val_loss: 0.0133 - val_mse: 0.0104\n",
      "Epoch 3/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0055\n",
      "Epoch 4/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0068 - val_loss: 0.0068 - val_mse: 0.0040\n",
      "Epoch 5/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0054 - val_loss: 0.0057 - val_mse: 0.0031\n",
      "Epoch 6/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0069 - mse: 0.0043 - val_loss: 0.0049 - val_mse: 0.0025\n",
      "Epoch 7/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0055 - mse: 0.0032 - val_loss: 0.0042 - val_mse: 0.0020\n",
      "Epoch 8/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0042 - mse: 0.0021 - val_loss: 0.0036 - val_mse: 0.0017\n",
      "Epoch 9/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0034 - mse: 0.0016 - val_loss: 0.0031 - val_mse: 0.0014\n",
      "Epoch 10/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0029 - mse: 0.0013 - val_loss: 0.0027 - val_mse: 0.0012\n",
      "Epoch 11/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0025 - mse: 0.0010 - val_loss: 0.0024 - val_mse: 9.9817e-04\n",
      "Epoch 12/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0023 - mse: 8.9136e-04 - val_loss: 0.0022 - val_mse: 8.7781e-04\n",
      "Epoch 13/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 8.0149e-04 - val_loss: 0.0020 - val_mse: 7.9599e-04\n",
      "Epoch 14/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 7.4881e-04 - val_loss: 0.0019 - val_mse: 7.4778e-04\n",
      "Epoch 15/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0018 - mse: 7.2125e-04 - val_loss: 0.0018 - val_mse: 7.2230e-04\n",
      "Epoch 16/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0018 - mse: 7.0573e-04 - val_loss: 0.0017 - val_mse: 7.0680e-04\n",
      "Epoch 17/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0017 - mse: 6.9815e-04 - val_loss: 0.0017 - val_mse: 6.9501e-04\n",
      "Epoch 18/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0016 - mse: 6.9151e-04 - val_loss: 0.0016 - val_mse: 6.8670e-04\n",
      "Epoch 19/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0016 - mse: 6.8616e-04 - val_loss: 0.0016 - val_mse: 6.8038e-04\n",
      "Epoch 20/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0015 - mse: 6.8086e-04 - val_loss: 0.0015 - val_mse: 6.7048e-04\n",
      "Epoch 21/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0015 - mse: 6.7436e-04 - val_loss: 0.0015 - val_mse: 6.6020e-04\n",
      "Epoch 22/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 6.6709e-04 - val_loss: 0.0014 - val_mse: 6.4908e-04\n",
      "Epoch 23/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 6.5831e-04 - val_loss: 0.0014 - val_mse: 6.3515e-04\n",
      "Epoch 24/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 6.4796e-04 - val_loss: 0.0013 - val_mse: 6.2205e-04\n",
      "Epoch 25/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 6.3888e-04 - val_loss: 0.0013 - val_mse: 6.0701e-04\n",
      "Epoch 26/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 6.2745e-04 - val_loss: 0.0012 - val_mse: 5.9161e-04\n",
      "Epoch 27/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 6.1621e-04 - val_loss: 0.0012 - val_mse: 5.7230e-04\n",
      "Epoch 28/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 6.0207e-04 - val_loss: 0.0011 - val_mse: 5.5263e-04\n",
      "Epoch 29/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 5.8791e-04 - val_loss: 0.0011 - val_mse: 5.3179e-04\n",
      "Epoch 30/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 5.7137e-04 - val_loss: 0.0010 - val_mse: 5.1169e-04\n",
      "Epoch 31/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 5.5531e-04 - val_loss: 9.9796e-04 - val_mse: 4.9219e-04\n",
      "Epoch 32/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0010 - mse: 5.3916e-04 - val_loss: 9.6560e-04 - val_mse: 4.7233e-04\n",
      "Epoch 33/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0010 - mse: 5.2168e-04 - val_loss: 9.3372e-04 - val_mse: 4.5409e-04\n",
      "Epoch 34/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 9.7859e-04 - mse: 5.0510e-04 - val_loss: 9.0445e-04 - val_mse: 4.3729e-04\n",
      "Epoch 35/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 9.5104e-04 - mse: 4.8860e-04 - val_loss: 8.7611e-04 - val_mse: 4.1927e-04\n",
      "Epoch 36/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 9.2560e-04 - mse: 4.7207e-04 - val_loss: 8.5237e-04 - val_mse: 4.0367e-04\n",
      "Epoch 37/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 9.0363e-04 - mse: 4.5731e-04 - val_loss: 8.3095e-04 - val_mse: 3.8896e-04\n",
      "Epoch 38/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.8210e-04 - mse: 4.4300e-04 - val_loss: 8.0968e-04 - val_mse: 3.7457e-04\n",
      "Epoch 39/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.6115e-04 - mse: 4.2894e-04 - val_loss: 7.8781e-04 - val_mse: 3.6167e-04\n",
      "Epoch 40/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.4082e-04 - mse: 4.1564e-04 - val_loss: 7.6753e-04 - val_mse: 3.4835e-04\n",
      "Epoch 41/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.2195e-04 - mse: 4.0283e-04 - val_loss: 7.4780e-04 - val_mse: 3.3621e-04\n",
      "Epoch 42/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.0187e-04 - mse: 3.9018e-04 - val_loss: 7.2885e-04 - val_mse: 3.2459e-04\n",
      "Epoch 43/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.8284e-04 - mse: 3.7838e-04 - val_loss: 7.1182e-04 - val_mse: 3.1433e-04\n",
      "Epoch 44/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.6389e-04 - mse: 3.6632e-04 - val_loss: 6.9428e-04 - val_mse: 3.0387e-04\n",
      "Epoch 45/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.4588e-04 - mse: 3.5486e-04 - val_loss: 6.7829e-04 - val_mse: 2.9401e-04\n",
      "Epoch 46/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.2891e-04 - mse: 3.4436e-04 - val_loss: 6.6075e-04 - val_mse: 2.8454e-04\n",
      "Epoch 47/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.1319e-04 - mse: 3.3497e-04 - val_loss: 6.4573e-04 - val_mse: 2.7546e-04\n",
      "Epoch 48/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.9798e-04 - mse: 3.2599e-04 - val_loss: 6.3268e-04 - val_mse: 2.6731e-04\n",
      "Epoch 49/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.8282e-04 - mse: 3.1602e-04 - val_loss: 6.1773e-04 - val_mse: 2.5935e-04\n",
      "Epoch 50/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.6866e-04 - mse: 3.0682e-04 - val_loss: 6.0585e-04 - val_mse: 2.5118e-04\n",
      "[ 09:28:18] getting statistics\n",
      "--------------------\n",
      "training window 38692\n",
      "Epoch 1/50\n",
      "137/137 [==============================] - 4s 6ms/step - loss: 0.1115 - mse: 0.1049 - val_loss: 0.0186 - val_mse: 0.0161\n",
      "Epoch 2/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0114 - val_loss: 0.0094 - val_mse: 0.0070\n",
      "Epoch 3/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0057 - val_loss: 0.0064 - val_mse: 0.0040\n",
      "Epoch 4/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0062 - mse: 0.0039 - val_loss: 0.0049 - val_mse: 0.0027\n",
      "Epoch 5/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0052 - mse: 0.0030 - val_loss: 0.0041 - val_mse: 0.0020\n",
      "Epoch 6/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0044 - mse: 0.0024 - val_loss: 0.0035 - val_mse: 0.0015\n",
      "Epoch 7/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0037 - mse: 0.0019 - val_loss: 0.0029 - val_mse: 0.0012\n",
      "Epoch 8/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0031 - mse: 0.0015 - val_loss: 0.0025 - val_mse: 9.0535e-04\n",
      "Epoch 9/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0027 - mse: 0.0011 - val_loss: 0.0022 - val_mse: 7.2975e-04\n",
      "Epoch 10/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0023 - mse: 9.1301e-04 - val_loss: 0.0019 - val_mse: 6.1229e-04\n",
      "Epoch 11/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0020 - mse: 7.4899e-04 - val_loss: 0.0018 - val_mse: 5.3467e-04\n",
      "Epoch 12/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0018 - mse: 6.4411e-04 - val_loss: 0.0016 - val_mse: 4.8252e-04\n",
      "Epoch 13/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0017 - mse: 5.8197e-04 - val_loss: 0.0015 - val_mse: 4.5596e-04\n",
      "Epoch 14/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0016 - mse: 5.4114e-04 - val_loss: 0.0014 - val_mse: 4.4088e-04\n",
      "Epoch 15/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0015 - mse: 5.0210e-04 - val_loss: 0.0014 - val_mse: 4.2178e-04\n",
      "Epoch 16/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 4.6857e-04 - val_loss: 0.0013 - val_mse: 3.8761e-04\n",
      "Epoch 17/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 4.2624e-04 - val_loss: 0.0012 - val_mse: 3.5282e-04\n",
      "Epoch 18/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 3.9448e-04 - val_loss: 0.0011 - val_mse: 3.1721e-04\n",
      "Epoch 19/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 3.6267e-04 - val_loss: 9.7849e-04 - val_mse: 2.8115e-04\n",
      "Epoch 20/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 9.9233e-04 - mse: 3.2563e-04 - val_loss: 8.8420e-04 - val_mse: 2.4834e-04\n",
      "Epoch 21/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.8727e-04 - mse: 2.8296e-04 - val_loss: 7.9668e-04 - val_mse: 2.1989e-04\n",
      "Epoch 22/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.8600e-04 - mse: 2.4183e-04 - val_loss: 7.1722e-04 - val_mse: 1.9792e-04\n",
      "Epoch 23/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.9890e-04 - mse: 2.0485e-04 - val_loss: 6.4663e-04 - val_mse: 1.7130e-04\n",
      "Epoch 24/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.3055e-04 - mse: 1.7640e-04 - val_loss: 5.7873e-04 - val_mse: 1.4270e-04\n",
      "Epoch 25/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.7356e-04 - mse: 1.5425e-04 - val_loss: 5.2207e-04 - val_mse: 1.1930e-04\n",
      "Epoch 26/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.2800e-04 - mse: 1.3785e-04 - val_loss: 4.8264e-04 - val_mse: 1.0732e-04\n",
      "Epoch 27/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.0009e-04 - mse: 1.3104e-04 - val_loss: 4.5177e-04 - val_mse: 9.4845e-05\n",
      "Epoch 28/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.7627e-04 - mse: 1.2437e-04 - val_loss: 4.2495e-04 - val_mse: 8.5338e-05\n",
      "Epoch 29/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.5114e-04 - mse: 1.1629e-04 - val_loss: 4.0647e-04 - val_mse: 7.9885e-05\n",
      "Epoch 30/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.3114e-04 - mse: 1.0814e-04 - val_loss: 3.9200e-04 - val_mse: 7.6114e-05\n",
      "Epoch 31/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.1795e-04 - mse: 1.0390e-04 - val_loss: 3.8176e-04 - val_mse: 7.2327e-05\n",
      "Epoch 32/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.1150e-04 - mse: 1.0369e-04 - val_loss: 3.7491e-04 - val_mse: 7.0290e-05\n",
      "Epoch 33/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.0964e-04 - mse: 1.0671e-04 - val_loss: 3.6456e-04 - val_mse: 6.7281e-05\n",
      "Epoch 34/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 3.9976e-04 - mse: 1.0349e-04 - val_loss: 3.5572e-04 - val_mse: 6.5441e-05\n",
      "Epoch 35/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 3.9493e-04 - mse: 1.0477e-04 - val_loss: 3.6083e-04 - val_mse: 7.4063e-05\n",
      "Epoch 36/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 3.9801e-04 - mse: 1.1086e-04 - val_loss: 3.4159e-04 - val_mse: 6.1260e-05\n",
      "Epoch 37/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 3.7881e-04 - mse: 9.9324e-05 - val_loss: 3.4377e-04 - val_mse: 6.7298e-05\n",
      "Epoch 38/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 3.8915e-04 - mse: 1.1148e-04 - val_loss: 3.3308e-04 - val_mse: 6.0013e-05\n",
      "Epoch 39/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 3.7626e-04 - mse: 1.0370e-04 - val_loss: 3.2821e-04 - val_mse: 5.9409e-05\n",
      "Epoch 40/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 3.6744e-04 - mse: 9.9378e-05 - val_loss: 3.2367e-04 - val_mse: 5.9051e-05\n",
      "Epoch 41/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 3.6800e-04 - mse: 1.0327e-04 - val_loss: 3.1894e-04 - val_mse: 5.7886e-05\n",
      "Epoch 42/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 3.5907e-04 - mse: 9.8906e-05 - val_loss: 3.1473e-04 - val_mse: 5.7826e-05\n",
      "Epoch 43/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 3.6302e-04 - mse: 1.0563e-04 - val_loss: 3.1296e-04 - val_mse: 5.8934e-05\n",
      "Epoch 44/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 3.4544e-04 - mse: 9.3271e-05 - val_loss: 3.0553e-04 - val_mse: 5.6602e-05\n",
      "Epoch 45/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 3.5323e-04 - mse: 1.0335e-04 - val_loss: 3.0375e-04 - val_mse: 5.6723e-05\n",
      "Epoch 46/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 3.5124e-04 - mse: 1.0431e-04 - val_loss: 3.0136e-04 - val_mse: 5.7881e-05\n",
      "Epoch 47/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 3.3637e-04 - mse: 9.4103e-05 - val_loss: 2.9593e-04 - val_mse: 5.6416e-05\n",
      "Epoch 48/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 3.4237e-04 - mse: 1.0224e-04 - val_loss: 2.9347e-04 - val_mse: 5.6844e-05\n",
      "Epoch 49/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 3.3044e-04 - mse: 9.4358e-05 - val_loss: 2.9232e-04 - val_mse: 5.8680e-05\n",
      "Epoch 50/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 3.3990e-04 - mse: 1.0552e-04 - val_loss: 2.8726e-04 - val_mse: 5.6456e-05\n",
      "[ 09:28:41] getting statistics\n",
      "--------------------\n",
      "training window 40968\n",
      "Epoch 1/50\n",
      "137/137 [==============================] - 3s 5ms/step - loss: 0.1067 - mse: 0.1001 - val_loss: 0.0179 - val_mse: 0.0152\n",
      "Epoch 2/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0135 - val_loss: 0.0100 - val_mse: 0.0072\n",
      "Epoch 3/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0067 - val_loss: 0.0076 - val_mse: 0.0046\n",
      "Epoch 4/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0044 - val_loss: 0.0067 - val_mse: 0.0039\n",
      "Epoch 5/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0061 - mse: 0.0035 - val_loss: 0.0061 - val_mse: 0.0035\n",
      "Epoch 6/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0053 - mse: 0.0028 - val_loss: 0.0057 - val_mse: 0.0032\n",
      "Epoch 7/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0046 - mse: 0.0023 - val_loss: 0.0052 - val_mse: 0.0030\n",
      "Epoch 8/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0039 - mse: 0.0019 - val_loss: 0.0046 - val_mse: 0.0027\n",
      "Epoch 9/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0033 - mse: 0.0014 - val_loss: 0.0039 - val_mse: 0.0022\n",
      "Epoch 10/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0028 - mse: 0.0011 - val_loss: 0.0033 - val_mse: 0.0018\n",
      "Epoch 11/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0024 - mse: 9.4840e-04 - val_loss: 0.0029 - val_mse: 0.0014\n",
      "Epoch 12/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0022 - mse: 8.1944e-04 - val_loss: 0.0025 - val_mse: 0.0011\n",
      "Epoch 13/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0020 - mse: 7.2045e-04 - val_loss: 0.0021 - val_mse: 8.9051e-04\n",
      "Epoch 14/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0018 - mse: 6.4695e-04 - val_loss: 0.0018 - val_mse: 7.0321e-04\n",
      "Epoch 15/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0017 - mse: 5.9543e-04 - val_loss: 0.0016 - val_mse: 5.6817e-04\n",
      "Epoch 16/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0016 - mse: 5.5920e-04 - val_loss: 0.0014 - val_mse: 4.7449e-04\n",
      "Epoch 17/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0015 - mse: 5.3235e-04 - val_loss: 0.0013 - val_mse: 4.2246e-04\n",
      "Epoch 18/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 5.1387e-04 - val_loss: 0.0012 - val_mse: 3.9934e-04\n",
      "Epoch 19/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 5.0075e-04 - val_loss: 0.0012 - val_mse: 3.9572e-04\n",
      "Epoch 20/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 4.9235e-04 - val_loss: 0.0011 - val_mse: 3.9954e-04\n",
      "Epoch 21/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 4.8713e-04 - val_loss: 0.0011 - val_mse: 4.0878e-04\n",
      "Epoch 22/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 4.8543e-04 - val_loss: 0.0011 - val_mse: 4.2374e-04\n",
      "Epoch 23/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 4.8543e-04 - val_loss: 0.0010 - val_mse: 4.3668e-04\n",
      "Epoch 24/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 4.8525e-04 - val_loss: 0.0010 - val_mse: 4.4622e-04\n",
      "Epoch 25/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0010 - mse: 4.8521e-04 - val_loss: 9.8596e-04 - val_mse: 4.5397e-04\n",
      "Epoch 26/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 9.8642e-04 - mse: 4.8464e-04 - val_loss: 9.5792e-04 - val_mse: 4.5629e-04\n",
      "Epoch 27/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 9.5893e-04 - mse: 4.8371e-04 - val_loss: 9.3490e-04 - val_mse: 4.5888e-04\n",
      "Epoch 28/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 9.3184e-04 - mse: 4.8174e-04 - val_loss: 9.0919e-04 - val_mse: 4.5586e-04\n",
      "Epoch 29/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 9.0608e-04 - mse: 4.7775e-04 - val_loss: 8.8107e-04 - val_mse: 4.4901e-04\n",
      "Epoch 30/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.8117e-04 - mse: 4.7336e-04 - val_loss: 8.5249e-04 - val_mse: 4.4184e-04\n",
      "Epoch 31/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.5744e-04 - mse: 4.6917e-04 - val_loss: 8.2699e-04 - val_mse: 4.3467e-04\n",
      "Epoch 32/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.3666e-04 - mse: 4.6389e-04 - val_loss: 8.0116e-04 - val_mse: 4.2280e-04\n",
      "Epoch 33/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.1735e-04 - mse: 4.5881e-04 - val_loss: 7.7487e-04 - val_mse: 4.1043e-04\n",
      "Epoch 34/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.9980e-04 - mse: 4.5299e-04 - val_loss: 7.5175e-04 - val_mse: 3.9827e-04\n",
      "Epoch 35/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.8262e-04 - mse: 4.4758e-04 - val_loss: 7.2747e-04 - val_mse: 3.8762e-04\n",
      "Epoch 36/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.6603e-04 - mse: 4.4242e-04 - val_loss: 7.0613e-04 - val_mse: 3.7670e-04\n",
      "Epoch 37/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.5158e-04 - mse: 4.3760e-04 - val_loss: 6.8440e-04 - val_mse: 3.6507e-04\n",
      "Epoch 38/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.3750e-04 - mse: 4.3261e-04 - val_loss: 6.6710e-04 - val_mse: 3.5569e-04\n",
      "Epoch 39/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.2509e-04 - mse: 4.2785e-04 - val_loss: 6.4983e-04 - val_mse: 3.4586e-04\n",
      "Epoch 40/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.1319e-04 - mse: 4.2341e-04 - val_loss: 6.3282e-04 - val_mse: 3.3601e-04\n",
      "Epoch 41/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.0205e-04 - mse: 4.1865e-04 - val_loss: 6.1599e-04 - val_mse: 3.2778e-04\n",
      "Epoch 42/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.9174e-04 - mse: 4.1431e-04 - val_loss: 6.0343e-04 - val_mse: 3.1924e-04\n",
      "Epoch 43/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.8274e-04 - mse: 4.0973e-04 - val_loss: 5.9003e-04 - val_mse: 3.1127e-04\n",
      "Epoch 44/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.7421e-04 - mse: 4.0561e-04 - val_loss: 5.7815e-04 - val_mse: 3.0481e-04\n",
      "Epoch 45/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.6572e-04 - mse: 4.0169e-04 - val_loss: 5.6833e-04 - val_mse: 2.9898e-04\n",
      "Epoch 46/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.5797e-04 - mse: 3.9826e-04 - val_loss: 5.5852e-04 - val_mse: 2.9333e-04\n",
      "Epoch 47/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.4961e-04 - mse: 3.9458e-04 - val_loss: 5.4877e-04 - val_mse: 2.8751e-04\n",
      "Epoch 48/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.4213e-04 - mse: 3.9107e-04 - val_loss: 5.3737e-04 - val_mse: 2.8160e-04\n",
      "Epoch 49/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.3501e-04 - mse: 3.8772e-04 - val_loss: 5.2918e-04 - val_mse: 2.7721e-04\n",
      "Epoch 50/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.2797e-04 - mse: 3.8460e-04 - val_loss: 5.2186e-04 - val_mse: 2.7313e-04\n",
      "[ 09:29:05] getting statistics\n",
      "--------------------\n",
      "training window 43244\n",
      "Epoch 1/50\n",
      "137/137 [==============================] - 3s 5ms/step - loss: 0.1062 - mse: 0.0994 - val_loss: 0.0162 - val_mse: 0.0134\n",
      "Epoch 2/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0115 - val_loss: 0.0085 - val_mse: 0.0058\n",
      "Epoch 3/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0052 - val_loss: 0.0057 - val_mse: 0.0032\n",
      "Epoch 4/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0059 - mse: 0.0035 - val_loss: 0.0047 - val_mse: 0.0024\n",
      "Epoch 5/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0049 - mse: 0.0027 - val_loss: 0.0040 - val_mse: 0.0019\n",
      "Epoch 6/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0041 - mse: 0.0021 - val_loss: 0.0034 - val_mse: 0.0015\n",
      "Epoch 7/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0033 - mse: 0.0015 - val_loss: 0.0029 - val_mse: 0.0012\n",
      "Epoch 8/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0026 - mse: 0.0011 - val_loss: 0.0023 - val_mse: 9.3312e-04\n",
      "Epoch 9/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 7.8649e-04 - val_loss: 0.0020 - val_mse: 7.3636e-04\n",
      "Epoch 10/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0018 - mse: 6.1340e-04 - val_loss: 0.0017 - val_mse: 6.2221e-04\n",
      "Epoch 11/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0016 - mse: 5.1579e-04 - val_loss: 0.0016 - val_mse: 5.6618e-04\n",
      "Epoch 12/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0015 - mse: 4.7255e-04 - val_loss: 0.0015 - val_mse: 5.3961e-04\n",
      "Epoch 13/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 4.5326e-04 - val_loss: 0.0014 - val_mse: 5.2750e-04\n",
      "Epoch 14/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 4.4216e-04 - val_loss: 0.0013 - val_mse: 5.1180e-04\n",
      "Epoch 15/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 4.3546e-04 - val_loss: 0.0012 - val_mse: 5.0222e-04\n",
      "Epoch 16/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 4.3126e-04 - val_loss: 0.0011 - val_mse: 4.9112e-04\n",
      "Epoch 17/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0010 - mse: 4.2807e-04 - val_loss: 0.0011 - val_mse: 4.8224e-04\n",
      "Epoch 18/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 9.8338e-04 - mse: 4.2519e-04 - val_loss: 9.9814e-04 - val_mse: 4.7386e-04\n",
      "Epoch 19/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 9.2454e-04 - mse: 4.2054e-04 - val_loss: 9.3702e-04 - val_mse: 4.6302e-04\n",
      "Epoch 20/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.7298e-04 - mse: 4.1174e-04 - val_loss: 8.8722e-04 - val_mse: 4.5021e-04\n",
      "Epoch 21/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.2710e-04 - mse: 4.0141e-04 - val_loss: 8.3901e-04 - val_mse: 4.3697e-04\n",
      "Epoch 22/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.8487e-04 - mse: 3.8923e-04 - val_loss: 8.0062e-04 - val_mse: 4.2301e-04\n",
      "Epoch 23/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.5108e-04 - mse: 3.7653e-04 - val_loss: 7.6959e-04 - val_mse: 4.0914e-04\n",
      "Epoch 24/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.2182e-04 - mse: 3.6397e-04 - val_loss: 7.4112e-04 - val_mse: 3.9597e-04\n",
      "Epoch 25/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.9465e-04 - mse: 3.5096e-04 - val_loss: 7.1582e-04 - val_mse: 3.8321e-04\n",
      "Epoch 26/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.7034e-04 - mse: 3.3809e-04 - val_loss: 6.9648e-04 - val_mse: 3.7186e-04\n",
      "Epoch 27/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.5059e-04 - mse: 3.2499e-04 - val_loss: 6.8143e-04 - val_mse: 3.6043e-04\n",
      "Epoch 28/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.3545e-04 - mse: 3.1345e-04 - val_loss: 6.7182e-04 - val_mse: 3.5306e-04\n",
      "Epoch 29/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.2130e-04 - mse: 3.0197e-04 - val_loss: 6.6119e-04 - val_mse: 3.4465e-04\n",
      "Epoch 30/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.0705e-04 - mse: 2.9066e-04 - val_loss: 6.5220e-04 - val_mse: 3.3714e-04\n",
      "Epoch 31/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.9363e-04 - mse: 2.8013e-04 - val_loss: 6.3899e-04 - val_mse: 3.2816e-04\n",
      "Epoch 32/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.8037e-04 - mse: 2.6970e-04 - val_loss: 6.2659e-04 - val_mse: 3.1914e-04\n",
      "Epoch 33/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 5.6746e-04 - mse: 2.5988e-04 - val_loss: 6.1607e-04 - val_mse: 3.1042e-04\n",
      "Epoch 34/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 5.5550e-04 - mse: 2.5087e-04 - val_loss: 6.0346e-04 - val_mse: 3.0055e-04\n",
      "Epoch 35/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.4379e-04 - mse: 2.4220e-04 - val_loss: 5.9107e-04 - val_mse: 2.9169e-04\n",
      "Epoch 36/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.3270e-04 - mse: 2.3425e-04 - val_loss: 5.7943e-04 - val_mse: 2.8279e-04\n",
      "Epoch 37/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.2188e-04 - mse: 2.2667e-04 - val_loss: 5.6655e-04 - val_mse: 2.7385e-04\n",
      "Epoch 38/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.1309e-04 - mse: 2.1943e-04 - val_loss: 5.5169e-04 - val_mse: 2.6384e-04\n",
      "Epoch 39/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.0253e-04 - mse: 2.1229e-04 - val_loss: 5.3868e-04 - val_mse: 2.5448e-04\n",
      "Epoch 40/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.9204e-04 - mse: 2.0526e-04 - val_loss: 5.2796e-04 - val_mse: 2.4696e-04\n",
      "Epoch 41/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.8249e-04 - mse: 1.9882e-04 - val_loss: 5.1528e-04 - val_mse: 2.3796e-04\n",
      "Epoch 42/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.7323e-04 - mse: 1.9308e-04 - val_loss: 5.0433e-04 - val_mse: 2.3095e-04\n",
      "Epoch 43/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.6356e-04 - mse: 1.8707e-04 - val_loss: 4.9332e-04 - val_mse: 2.2373e-04\n",
      "Epoch 44/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.5507e-04 - mse: 1.8178e-04 - val_loss: 4.8188e-04 - val_mse: 2.1610e-04\n",
      "Epoch 45/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.4698e-04 - mse: 1.7710e-04 - val_loss: 4.7444e-04 - val_mse: 2.1119e-04\n",
      "Epoch 46/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.3908e-04 - mse: 1.7258e-04 - val_loss: 4.6430e-04 - val_mse: 2.0448e-04\n",
      "Epoch 47/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.3171e-04 - mse: 1.6851e-04 - val_loss: 4.5382e-04 - val_mse: 1.9725e-04\n",
      "Epoch 48/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.2481e-04 - mse: 1.6518e-04 - val_loss: 4.4132e-04 - val_mse: 1.8805e-04\n",
      "Epoch 49/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.1791e-04 - mse: 1.6162e-04 - val_loss: 4.3109e-04 - val_mse: 1.8149e-04\n",
      "Epoch 50/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.1129e-04 - mse: 1.5840e-04 - val_loss: 4.2073e-04 - val_mse: 1.7376e-04\n",
      "[ 09:29:29] getting statistics\n",
      "--------------------\n",
      "training window 45520\n",
      "Epoch 1/50\n",
      "137/137 [==============================] - 3s 6ms/step - loss: 0.1495 - mse: 0.1433 - val_loss: 0.0254 - val_mse: 0.0230\n",
      "Epoch 2/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0139 - val_loss: 0.0141 - val_mse: 0.0118\n",
      "Epoch 3/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0104 - mse: 0.0079 - val_loss: 0.0100 - val_mse: 0.0074\n",
      "Epoch 4/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0048 - val_loss: 0.0082 - val_mse: 0.0056\n",
      "Epoch 5/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0059 - mse: 0.0033 - val_loss: 0.0075 - val_mse: 0.0050\n",
      "Epoch 6/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0050 - mse: 0.0026 - val_loss: 0.0070 - val_mse: 0.0046\n",
      "Epoch 7/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0044 - mse: 0.0020 - val_loss: 0.0064 - val_mse: 0.0041\n",
      "Epoch 8/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0037 - mse: 0.0015 - val_loss: 0.0054 - val_mse: 0.0034\n",
      "Epoch 9/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0031 - mse: 0.0012 - val_loss: 0.0045 - val_mse: 0.0027\n",
      "Epoch 10/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0027 - mse: 0.0010 - val_loss: 0.0038 - val_mse: 0.0022\n",
      "Epoch 11/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0024 - mse: 9.4094e-04 - val_loss: 0.0032 - val_mse: 0.0018\n",
      "Epoch 12/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0022 - mse: 8.6108e-04 - val_loss: 0.0028 - val_mse: 0.0015\n",
      "Epoch 13/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0020 - mse: 7.9712e-04 - val_loss: 0.0024 - val_mse: 0.0013\n",
      "Epoch 14/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0018 - mse: 7.4726e-04 - val_loss: 0.0022 - val_mse: 0.0012\n",
      "Epoch 15/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0017 - mse: 7.0950e-04 - val_loss: 0.0020 - val_mse: 0.0011\n",
      "Epoch 16/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.0016 - mse: 6.8038e-04 - val_loss: 0.0019 - val_mse: 9.8822e-04\n",
      "Epoch 17/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0015 - mse: 6.5712e-04 - val_loss: 0.0018 - val_mse: 9.2950e-04\n",
      "Epoch 18/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0015 - mse: 6.3859e-04 - val_loss: 0.0017 - val_mse: 8.8161e-04\n",
      "Epoch 19/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 6.2254e-04 - val_loss: 0.0016 - val_mse: 8.4248e-04\n",
      "Epoch 20/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 6.0873e-04 - val_loss: 0.0015 - val_mse: 8.0591e-04\n",
      "Epoch 21/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 5.9835e-04 - val_loss: 0.0014 - val_mse: 7.8015e-04\n",
      "Epoch 22/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 5.8815e-04 - val_loss: 0.0014 - val_mse: 7.5438e-04\n",
      "Epoch 23/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 5.8050e-04 - val_loss: 0.0013 - val_mse: 7.3816e-04\n",
      "Epoch 24/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 5.7290e-04 - val_loss: 0.0012 - val_mse: 7.1915e-04\n",
      "Epoch 25/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 5.6662e-04 - val_loss: 0.0012 - val_mse: 7.0280e-04\n",
      "Epoch 26/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0010 - mse: 5.6090e-04 - val_loss: 0.0011 - val_mse: 6.8925e-04\n",
      "Epoch 27/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 9.8891e-04 - mse: 5.5522e-04 - val_loss: 0.0011 - val_mse: 6.7948e-04\n",
      "Epoch 28/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 9.5220e-04 - mse: 5.4967e-04 - val_loss: 0.0011 - val_mse: 6.7276e-04\n",
      "Epoch 29/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 9.1859e-04 - mse: 5.4392e-04 - val_loss: 0.0010 - val_mse: 6.7103e-04\n",
      "Epoch 30/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.8859e-04 - mse: 5.3713e-04 - val_loss: 0.0010 - val_mse: 6.6370e-04\n",
      "Epoch 31/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.6423e-04 - mse: 5.2927e-04 - val_loss: 9.8129e-04 - val_mse: 6.5628e-04\n",
      "Epoch 32/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.4206e-04 - mse: 5.2232e-04 - val_loss: 9.6159e-04 - val_mse: 6.5075e-04\n",
      "Epoch 33/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.2270e-04 - mse: 5.1505e-04 - val_loss: 9.4203e-04 - val_mse: 6.4082e-04\n",
      "Epoch 34/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.0567e-04 - mse: 5.0778e-04 - val_loss: 9.2758e-04 - val_mse: 6.3556e-04\n",
      "Epoch 35/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.9069e-04 - mse: 5.0071e-04 - val_loss: 9.1389e-04 - val_mse: 6.2752e-04\n",
      "Epoch 36/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.7823e-04 - mse: 4.9368e-04 - val_loss: 9.0298e-04 - val_mse: 6.2088e-04\n",
      "Epoch 37/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.6743e-04 - mse: 4.8672e-04 - val_loss: 8.9203e-04 - val_mse: 6.1360e-04\n",
      "Epoch 38/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.5730e-04 - mse: 4.8016e-04 - val_loss: 8.8177e-04 - val_mse: 6.0608e-04\n",
      "Epoch 39/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.4808e-04 - mse: 4.7408e-04 - val_loss: 8.7133e-04 - val_mse: 5.9920e-04\n",
      "Epoch 40/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.3968e-04 - mse: 4.6803e-04 - val_loss: 8.6575e-04 - val_mse: 5.9461e-04\n",
      "Epoch 41/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.3142e-04 - mse: 4.6251e-04 - val_loss: 8.5812e-04 - val_mse: 5.8877e-04\n",
      "Epoch 42/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.2404e-04 - mse: 4.5712e-04 - val_loss: 8.5091e-04 - val_mse: 5.8372e-04\n",
      "Epoch 43/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.1644e-04 - mse: 4.5127e-04 - val_loss: 8.4191e-04 - val_mse: 5.7638e-04\n",
      "Epoch 44/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.0981e-04 - mse: 4.4596e-04 - val_loss: 8.3607e-04 - val_mse: 5.7032e-04\n",
      "Epoch 45/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.0333e-04 - mse: 4.4105e-04 - val_loss: 8.2714e-04 - val_mse: 5.6398e-04\n",
      "Epoch 46/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.9698e-04 - mse: 4.3671e-04 - val_loss: 8.1938e-04 - val_mse: 5.5847e-04\n",
      "Epoch 47/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.9081e-04 - mse: 4.3206e-04 - val_loss: 8.1372e-04 - val_mse: 5.5396e-04\n",
      "Epoch 48/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.8476e-04 - mse: 4.2799e-04 - val_loss: 8.0559e-04 - val_mse: 5.4776e-04\n",
      "Epoch 49/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.7937e-04 - mse: 4.2468e-04 - val_loss: 8.0279e-04 - val_mse: 5.4679e-04\n",
      "Epoch 50/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.7321e-04 - mse: 4.2057e-04 - val_loss: 7.9882e-04 - val_mse: 5.4389e-04\n",
      "[ 09:29:53] getting statistics\n",
      "--------------------\n",
      "training window 47796\n",
      "Epoch 1/50\n",
      "137/137 [==============================] - 3s 6ms/step - loss: 0.1075 - mse: 0.1010 - val_loss: 0.0236 - val_mse: 0.0209\n",
      "Epoch 2/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0156 - val_loss: 0.0114 - val_mse: 0.0084\n",
      "Epoch 3/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0104 - mse: 0.0074 - val_loss: 0.0073 - val_mse: 0.0043\n",
      "Epoch 4/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0049 - val_loss: 0.0056 - val_mse: 0.0030\n",
      "Epoch 5/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0062 - mse: 0.0037 - val_loss: 0.0046 - val_mse: 0.0022\n",
      "Epoch 6/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0050 - mse: 0.0027 - val_loss: 0.0038 - val_mse: 0.0017\n",
      "Epoch 7/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0039 - mse: 0.0019 - val_loss: 0.0031 - val_mse: 0.0013\n",
      "Epoch 8/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0032 - mse: 0.0014 - val_loss: 0.0026 - val_mse: 9.5304e-04\n",
      "Epoch 9/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0027 - mse: 0.0011 - val_loss: 0.0022 - val_mse: 7.3324e-04\n",
      "Epoch 10/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0023 - mse: 8.7661e-04 - val_loss: 0.0019 - val_mse: 5.9282e-04\n",
      "Epoch 11/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0020 - mse: 7.5111e-04 - val_loss: 0.0017 - val_mse: 5.1480e-04\n",
      "Epoch 12/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 6.8350e-04 - val_loss: 0.0016 - val_mse: 4.7725e-04\n",
      "Epoch 13/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0017 - mse: 6.5310e-04 - val_loss: 0.0015 - val_mse: 4.7025e-04\n",
      "Epoch 14/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0017 - mse: 6.4262e-04 - val_loss: 0.0014 - val_mse: 4.7607e-04\n",
      "Epoch 15/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0016 - mse: 6.3782e-04 - val_loss: 0.0014 - val_mse: 4.8982e-04\n",
      "Epoch 16/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0015 - mse: 6.3635e-04 - val_loss: 0.0013 - val_mse: 5.0305e-04\n",
      "Epoch 17/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 6.3575e-04 - val_loss: 0.0013 - val_mse: 5.1091e-04\n",
      "Epoch 18/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 6.3518e-04 - val_loss: 0.0012 - val_mse: 5.1746e-04\n",
      "Epoch 19/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 6.3384e-04 - val_loss: 0.0012 - val_mse: 5.2369e-04\n",
      "Epoch 20/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 6.3123e-04 - val_loss: 0.0011 - val_mse: 5.2262e-04\n",
      "Epoch 21/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 6.2633e-04 - val_loss: 0.0011 - val_mse: 5.2111e-04\n",
      "Epoch 22/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 6.2086e-04 - val_loss: 0.0010 - val_mse: 5.1991e-04\n",
      "Epoch 23/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 6.1533e-04 - val_loss: 9.9563e-04 - val_mse: 5.1789e-04\n",
      "Epoch 24/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 6.0763e-04 - val_loss: 9.6596e-04 - val_mse: 5.1306e-04\n",
      "Epoch 25/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0010 - mse: 5.9928e-04 - val_loss: 9.4019e-04 - val_mse: 5.0516e-04\n",
      "Epoch 26/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0010 - mse: 5.9064e-04 - val_loss: 9.1261e-04 - val_mse: 4.9403e-04\n",
      "Epoch 27/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 9.9825e-04 - mse: 5.8042e-04 - val_loss: 8.9073e-04 - val_mse: 4.8227e-04\n",
      "Epoch 28/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 9.6000e-04 - mse: 5.5383e-04 - val_loss: 8.2434e-04 - val_mse: 4.2571e-04\n",
      "Epoch 29/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.8162e-04 - mse: 4.8948e-04 - val_loss: 7.2125e-04 - val_mse: 3.3504e-04\n",
      "Epoch 30/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.9089e-04 - mse: 4.1374e-04 - val_loss: 6.2978e-04 - val_mse: 2.5867e-04\n",
      "Epoch 31/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.1574e-04 - mse: 3.5246e-04 - val_loss: 5.6814e-04 - val_mse: 2.0916e-04\n",
      "Epoch 32/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.5676e-04 - mse: 3.0629e-04 - val_loss: 5.1976e-04 - val_mse: 1.7157e-04\n",
      "Epoch 33/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.1074e-04 - mse: 2.7242e-04 - val_loss: 4.8489e-04 - val_mse: 1.4880e-04\n",
      "Epoch 34/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.7442e-04 - mse: 2.4782e-04 - val_loss: 4.6413e-04 - val_mse: 1.3747e-04\n",
      "Epoch 35/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.4633e-04 - mse: 2.3044e-04 - val_loss: 4.5067e-04 - val_mse: 1.3469e-04\n",
      "Epoch 36/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.2165e-04 - mse: 2.1653e-04 - val_loss: 4.3935e-04 - val_mse: 1.3319e-04\n",
      "Epoch 37/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.0171e-04 - mse: 2.0571e-04 - val_loss: 4.3002e-04 - val_mse: 1.3099e-04\n",
      "Epoch 38/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.8610e-04 - mse: 1.9748e-04 - val_loss: 4.1954e-04 - val_mse: 1.2804e-04\n",
      "Epoch 39/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.7051e-04 - mse: 1.8877e-04 - val_loss: 4.1698e-04 - val_mse: 1.3157e-04\n",
      "Epoch 40/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.5940e-04 - mse: 1.8433e-04 - val_loss: 4.1412e-04 - val_mse: 1.3630e-04\n",
      "Epoch 41/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.4975e-04 - mse: 1.8095e-04 - val_loss: 4.1490e-04 - val_mse: 1.4249e-04\n",
      "Epoch 42/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.4275e-04 - mse: 1.7884e-04 - val_loss: 4.1206e-04 - val_mse: 1.4416e-04\n",
      "Epoch 43/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.3618e-04 - mse: 1.7581e-04 - val_loss: 4.0970e-04 - val_mse: 1.4470e-04\n",
      "Epoch 44/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.2881e-04 - mse: 1.7094e-04 - val_loss: 4.1662e-04 - val_mse: 1.5434e-04\n",
      "Epoch 45/50\n",
      "137/137 [==============================] - 0s 4ms/step - loss: 4.2426e-04 - mse: 1.6899e-04 - val_loss: 4.1604e-04 - val_mse: 1.5736e-04\n",
      "Epoch 46/50\n",
      "137/137 [==============================] - 0s 4ms/step - loss: 4.1970e-04 - mse: 1.6708e-04 - val_loss: 4.1881e-04 - val_mse: 1.6266e-04\n",
      "Epoch 47/50\n",
      "137/137 [==============================] - 0s 4ms/step - loss: 4.1544e-04 - mse: 1.6549e-04 - val_loss: 4.1790e-04 - val_mse: 1.6433e-04\n",
      "Epoch 48/50\n",
      "137/137 [==============================] - 0s 4ms/step - loss: 4.1153e-04 - mse: 1.6386e-04 - val_loss: 4.1943e-04 - val_mse: 1.6964e-04\n",
      "Epoch 49/50\n",
      "137/137 [==============================] - 0s 4ms/step - loss: 4.0816e-04 - mse: 1.6292e-04 - val_loss: 4.2186e-04 - val_mse: 1.7387e-04\n",
      "Epoch 50/50\n",
      "137/137 [==============================] - 0s 4ms/step - loss: 4.0509e-04 - mse: 1.6236e-04 - val_loss: 4.2201e-04 - val_mse: 1.7656e-04\n",
      "[ 09:30:18] getting statistics\n",
      "--------------------\n",
      "training window 50072\n",
      "Epoch 1/50\n",
      "137/137 [==============================] - 4s 6ms/step - loss: 0.1277 - mse: 0.1216 - val_loss: 0.0403 - val_mse: 0.0384\n",
      "Epoch 2/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0213 - val_loss: 0.0117 - val_mse: 0.0089\n",
      "Epoch 3/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0100 - val_loss: 0.0080 - val_mse: 0.0050\n",
      "Epoch 4/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0065 - val_loss: 0.0062 - val_mse: 0.0035\n",
      "Epoch 5/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0047 - val_loss: 0.0052 - val_mse: 0.0026\n",
      "Epoch 6/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0059 - mse: 0.0034 - val_loss: 0.0043 - val_mse: 0.0020\n",
      "Epoch 7/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0047 - mse: 0.0024 - val_loss: 0.0038 - val_mse: 0.0017\n",
      "Epoch 8/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0039 - mse: 0.0019 - val_loss: 0.0033 - val_mse: 0.0015\n",
      "Epoch 9/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0034 - mse: 0.0016 - val_loss: 0.0029 - val_mse: 0.0013\n",
      "Epoch 10/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0030 - mse: 0.0014 - val_loss: 0.0026 - val_mse: 0.0011\n",
      "Epoch 11/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0027 - mse: 0.0012 - val_loss: 0.0024 - val_mse: 0.0010\n",
      "Epoch 12/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0024 - mse: 0.0011 - val_loss: 0.0022 - val_mse: 9.0989e-04\n",
      "Epoch 13/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0023 - mse: 9.8190e-04 - val_loss: 0.0021 - val_mse: 8.2284e-04\n",
      "Epoch 14/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 8.9003e-04 - val_loss: 0.0019 - val_mse: 7.3207e-04\n",
      "Epoch 15/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 7.8149e-04 - val_loss: 0.0018 - val_mse: 6.3786e-04\n",
      "Epoch 16/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0018 - mse: 6.7691e-04 - val_loss: 0.0016 - val_mse: 5.6336e-04\n",
      "Epoch 17/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0017 - mse: 6.0809e-04 - val_loss: 0.0015 - val_mse: 5.0181e-04\n",
      "Epoch 18/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0015 - mse: 5.5272e-04 - val_loss: 0.0014 - val_mse: 4.4484e-04\n",
      "Epoch 19/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 5.0398e-04 - val_loss: 0.0013 - val_mse: 3.9125e-04\n",
      "Epoch 20/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 4.5729e-04 - val_loss: 0.0012 - val_mse: 3.4235e-04\n",
      "Epoch 21/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 4.1159e-04 - val_loss: 0.0011 - val_mse: 2.9809e-04\n",
      "Epoch 22/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 3.6426e-04 - val_loss: 0.0010 - val_mse: 2.6131e-04\n",
      "Epoch 23/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0010 - mse: 3.1862e-04 - val_loss: 9.3121e-04 - val_mse: 2.3850e-04\n",
      "Epoch 24/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 9.4224e-04 - mse: 2.7698e-04 - val_loss: 8.5738e-04 - val_mse: 2.2300e-04\n",
      "Epoch 25/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.4801e-04 - mse: 2.4093e-04 - val_loss: 7.6795e-04 - val_mse: 1.9405e-04\n",
      "Epoch 26/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.6294e-04 - mse: 2.1627e-04 - val_loss: 6.8738e-04 - val_mse: 1.7300e-04\n",
      "Epoch 27/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.8821e-04 - mse: 1.9995e-04 - val_loss: 6.3186e-04 - val_mse: 1.7394e-04\n",
      "Epoch 28/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.4227e-04 - mse: 2.0652e-04 - val_loss: 5.6022e-04 - val_mse: 1.5198e-04\n",
      "Epoch 29/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.8850e-04 - mse: 1.9736e-04 - val_loss: 4.9491e-04 - val_mse: 1.2244e-04\n",
      "Epoch 30/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.4227e-04 - mse: 1.8724e-04 - val_loss: 4.7558e-04 - val_mse: 1.3338e-04\n",
      "Epoch 31/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.3816e-04 - mse: 2.0739e-04 - val_loss: 4.5655e-04 - val_mse: 1.3135e-04\n",
      "Epoch 32/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.1410e-04 - mse: 2.9322e-04 - val_loss: 5.3897e-04 - val_mse: 2.3762e-04\n",
      "Epoch 33/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.9030e-04 - mse: 1.9480e-04 - val_loss: 4.1934e-04 - val_mse: 1.3587e-04\n",
      "Epoch 34/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.6679e-04 - mse: 1.8509e-04 - val_loss: 4.1636e-04 - val_mse: 1.3631e-04\n",
      "Epoch 35/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.5597e-04 - mse: 1.8403e-04 - val_loss: 4.0134e-04 - val_mse: 1.2884e-04\n",
      "Epoch 36/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.6778e-04 - mse: 2.0268e-04 - val_loss: 4.1810e-04 - val_mse: 1.5184e-04\n",
      "Epoch 37/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.4112e-04 - mse: 1.8511e-04 - val_loss: 3.8947e-04 - val_mse: 1.3244e-04\n",
      "Epoch 38/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.4086e-04 - mse: 1.9066e-04 - val_loss: 3.9034e-04 - val_mse: 1.3811e-04\n",
      "Epoch 39/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.3438e-04 - mse: 1.8971e-04 - val_loss: 3.8897e-04 - val_mse: 1.4158e-04\n",
      "Epoch 40/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.2698e-04 - mse: 1.8770e-04 - val_loss: 3.8235e-04 - val_mse: 1.4091e-04\n",
      "Epoch 41/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.1682e-04 - mse: 1.8195e-04 - val_loss: 3.6542e-04 - val_mse: 1.2734e-04\n",
      "Epoch 42/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.2110e-04 - mse: 1.8846e-04 - val_loss: 3.9327e-04 - val_mse: 1.5719e-04\n",
      "Epoch 43/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.0967e-04 - mse: 1.8161e-04 - val_loss: 3.8126e-04 - val_mse: 1.4960e-04\n",
      "Epoch 44/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.0797e-04 - mse: 1.8291e-04 - val_loss: 3.8095e-04 - val_mse: 1.5200e-04\n",
      "Epoch 45/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.0462e-04 - mse: 1.8250e-04 - val_loss: 3.7983e-04 - val_mse: 1.5203e-04\n",
      "Epoch 46/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.0017e-04 - mse: 1.8036e-04 - val_loss: 3.7853e-04 - val_mse: 1.5517e-04\n",
      "Epoch 47/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 3.9443e-04 - mse: 1.7704e-04 - val_loss: 3.7309e-04 - val_mse: 1.5263e-04\n",
      "Epoch 48/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 3.9223e-04 - mse: 1.7773e-04 - val_loss: 3.7197e-04 - val_mse: 1.5312e-04\n",
      "Epoch 49/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 3.9073e-04 - mse: 1.7822e-04 - val_loss: 3.7267e-04 - val_mse: 1.5574e-04\n",
      "Epoch 50/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 3.8797e-04 - mse: 1.7770e-04 - val_loss: 3.6897e-04 - val_mse: 1.5369e-04\n",
      "[ 09:30:42] getting statistics\n",
      "--------------------\n",
      "training window 52348\n",
      "Epoch 1/50\n",
      "137/137 [==============================] - 4s 6ms/step - loss: 0.1187 - mse: 0.1126 - val_loss: 0.0285 - val_mse: 0.0264\n",
      "Epoch 2/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0168 - val_loss: 0.0126 - val_mse: 0.0102\n",
      "Epoch 3/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0111 - mse: 0.0085 - val_loss: 0.0087 - val_mse: 0.0060\n",
      "Epoch 4/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0057 - val_loss: 0.0070 - val_mse: 0.0044\n",
      "Epoch 5/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0045 - val_loss: 0.0060 - val_mse: 0.0035\n",
      "Epoch 6/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0061 - mse: 0.0037 - val_loss: 0.0053 - val_mse: 0.0028\n",
      "Epoch 7/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0053 - mse: 0.0030 - val_loss: 0.0046 - val_mse: 0.0023\n",
      "Epoch 8/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0046 - mse: 0.0024 - val_loss: 0.0038 - val_mse: 0.0018\n",
      "Epoch 9/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0038 - mse: 0.0019 - val_loss: 0.0032 - val_mse: 0.0013\n",
      "Epoch 10/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0032 - mse: 0.0015 - val_loss: 0.0026 - val_mse: 0.0010\n",
      "Epoch 11/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0028 - mse: 0.0013 - val_loss: 0.0023 - val_mse: 8.3044e-04\n",
      "Epoch 12/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0025 - mse: 0.0011 - val_loss: 0.0020 - val_mse: 6.9506e-04\n",
      "Epoch 13/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0022 - mse: 9.4587e-04 - val_loss: 0.0019 - val_mse: 6.1165e-04\n",
      "Epoch 14/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 8.4506e-04 - val_loss: 0.0017 - val_mse: 5.4997e-04\n",
      "Epoch 15/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 7.5922e-04 - val_loss: 0.0016 - val_mse: 4.9601e-04\n",
      "Epoch 16/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0018 - mse: 6.8720e-04 - val_loss: 0.0015 - val_mse: 4.5762e-04\n",
      "Epoch 17/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0017 - mse: 6.2829e-04 - val_loss: 0.0014 - val_mse: 4.3067e-04\n",
      "Epoch 18/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0016 - mse: 5.8180e-04 - val_loss: 0.0014 - val_mse: 4.1409e-04\n",
      "Epoch 19/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0015 - mse: 5.4401e-04 - val_loss: 0.0013 - val_mse: 4.0392e-04\n",
      "Epoch 20/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 5.2148e-04 - val_loss: 0.0013 - val_mse: 3.9742e-04\n",
      "Epoch 21/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 5.0879e-04 - val_loss: 0.0012 - val_mse: 3.9081e-04\n",
      "Epoch 22/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 5.0007e-04 - val_loss: 0.0012 - val_mse: 3.8420e-04\n",
      "Epoch 23/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 4.9243e-04 - val_loss: 0.0011 - val_mse: 3.7678e-04\n",
      "Epoch 24/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 4.8655e-04 - val_loss: 0.0010 - val_mse: 3.7135e-04\n",
      "Epoch 25/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 4.8143e-04 - val_loss: 0.0010 - val_mse: 3.6752e-04\n",
      "Epoch 26/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 4.7531e-04 - val_loss: 9.6044e-04 - val_mse: 3.6308e-04\n",
      "Epoch 27/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 4.6786e-04 - val_loss: 9.2058e-04 - val_mse: 3.5821e-04\n",
      "Epoch 28/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0010 - mse: 4.5953e-04 - val_loss: 8.8105e-04 - val_mse: 3.5336e-04\n",
      "Epoch 29/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 9.6959e-04 - mse: 4.5042e-04 - val_loss: 8.4677e-04 - val_mse: 3.4637e-04\n",
      "Epoch 30/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 9.3318e-04 - mse: 4.4071e-04 - val_loss: 8.1357e-04 - val_mse: 3.3936e-04\n",
      "Epoch 31/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.9803e-04 - mse: 4.3080e-04 - val_loss: 7.8077e-04 - val_mse: 3.3213e-04\n",
      "Epoch 32/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.6373e-04 - mse: 4.2001e-04 - val_loss: 7.5205e-04 - val_mse: 3.2465e-04\n",
      "Epoch 33/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.3325e-04 - mse: 4.0939e-04 - val_loss: 7.2344e-04 - val_mse: 3.1651e-04\n",
      "Epoch 34/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.0422e-04 - mse: 3.9874e-04 - val_loss: 6.9759e-04 - val_mse: 3.0898e-04\n",
      "Epoch 35/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.7717e-04 - mse: 3.8876e-04 - val_loss: 6.7306e-04 - val_mse: 3.0124e-04\n",
      "Epoch 36/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.5101e-04 - mse: 3.7871e-04 - val_loss: 6.4858e-04 - val_mse: 2.9344e-04\n",
      "Epoch 37/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.2619e-04 - mse: 3.6894e-04 - val_loss: 6.2622e-04 - val_mse: 2.8573e-04\n",
      "Epoch 38/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.0162e-04 - mse: 3.5914e-04 - val_loss: 6.0450e-04 - val_mse: 2.7790e-04\n",
      "Epoch 39/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.7811e-04 - mse: 3.4841e-04 - val_loss: 5.8471e-04 - val_mse: 2.7004e-04\n",
      "Epoch 40/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.5730e-04 - mse: 3.3792e-04 - val_loss: 5.6893e-04 - val_mse: 2.6220e-04\n",
      "Epoch 41/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.3921e-04 - mse: 3.2521e-04 - val_loss: 5.5643e-04 - val_mse: 2.5350e-04\n",
      "Epoch 42/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.2414e-04 - mse: 3.1422e-04 - val_loss: 5.4378e-04 - val_mse: 2.4556e-04\n",
      "Epoch 43/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.0940e-04 - mse: 3.0388e-04 - val_loss: 5.3231e-04 - val_mse: 2.3781e-04\n",
      "Epoch 44/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.9556e-04 - mse: 2.9418e-04 - val_loss: 5.2099e-04 - val_mse: 2.3034e-04\n",
      "Epoch 45/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.8247e-04 - mse: 2.8527e-04 - val_loss: 5.0994e-04 - val_mse: 2.2328e-04\n",
      "Epoch 46/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.6999e-04 - mse: 2.7707e-04 - val_loss: 4.9827e-04 - val_mse: 2.1641e-04\n",
      "Epoch 47/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.5743e-04 - mse: 2.6903e-04 - val_loss: 4.8756e-04 - val_mse: 2.0962e-04\n",
      "Epoch 48/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.4510e-04 - mse: 2.6110e-04 - val_loss: 4.7712e-04 - val_mse: 2.0334e-04\n",
      "Epoch 49/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.3321e-04 - mse: 2.5312e-04 - val_loss: 4.6729e-04 - val_mse: 1.9682e-04\n",
      "Epoch 50/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.2200e-04 - mse: 2.4533e-04 - val_loss: 4.5777e-04 - val_mse: 1.9088e-04\n",
      "[ 09:31:06] getting statistics\n",
      "--------------------\n",
      "training window 54624\n",
      "Epoch 1/50\n",
      "137/137 [==============================] - 4s 6ms/step - loss: 0.1092 - mse: 0.1027 - val_loss: 0.0248 - val_mse: 0.0222\n",
      "Epoch 2/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0169 - val_loss: 0.0153 - val_mse: 0.0129\n",
      "Epoch 3/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0080 - val_loss: 0.0102 - val_mse: 0.0076\n",
      "Epoch 4/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0047 - val_loss: 0.0078 - val_mse: 0.0053\n",
      "Epoch 5/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0059 - mse: 0.0035 - val_loss: 0.0065 - val_mse: 0.0042\n",
      "Epoch 6/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0051 - mse: 0.0028 - val_loss: 0.0058 - val_mse: 0.0036\n",
      "Epoch 7/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0047 - mse: 0.0024 - val_loss: 0.0053 - val_mse: 0.0032\n",
      "Epoch 8/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0042 - mse: 0.0021 - val_loss: 0.0049 - val_mse: 0.0029\n",
      "Epoch 9/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0038 - mse: 0.0018 - val_loss: 0.0045 - val_mse: 0.0026\n",
      "Epoch 10/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0034 - mse: 0.0016 - val_loss: 0.0040 - val_mse: 0.0023\n",
      "Epoch 11/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0029 - mse: 0.0013 - val_loss: 0.0034 - val_mse: 0.0019\n",
      "Epoch 12/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0025 - mse: 0.0010 - val_loss: 0.0029 - val_mse: 0.0015\n",
      "Epoch 13/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 8.2523e-04 - val_loss: 0.0024 - val_mse: 0.0012\n",
      "Epoch 14/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 6.9778e-04 - val_loss: 0.0021 - val_mse: 9.4319e-04\n",
      "Epoch 15/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0017 - mse: 6.2397e-04 - val_loss: 0.0019 - val_mse: 8.0443e-04\n",
      "Epoch 16/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0016 - mse: 5.7870e-04 - val_loss: 0.0017 - val_mse: 7.1684e-04\n",
      "Epoch 17/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0015 - mse: 5.5048e-04 - val_loss: 0.0016 - val_mse: 6.7840e-04\n",
      "Epoch 18/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 5.3551e-04 - val_loss: 0.0015 - val_mse: 6.7531e-04\n",
      "Epoch 19/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 5.2867e-04 - val_loss: 0.0015 - val_mse: 6.7831e-04\n",
      "Epoch 20/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 5.2590e-04 - val_loss: 0.0014 - val_mse: 6.8547e-04\n",
      "Epoch 21/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 5.2390e-04 - val_loss: 0.0014 - val_mse: 6.8572e-04\n",
      "Epoch 22/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.0012 - mse: 5.1952e-04 - val_loss: 0.0014 - val_mse: 6.8943e-04\n",
      "Epoch 23/50\n",
      "137/137 [==============================] - 0s 4ms/step - loss: 0.0012 - mse: 5.1489e-04 - val_loss: 0.0013 - val_mse: 6.9035e-04\n",
      "Epoch 24/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.0011 - mse: 5.1018e-04 - val_loss: 0.0013 - val_mse: 6.9480e-04\n",
      "Epoch 25/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.0011 - mse: 5.0406e-04 - val_loss: 0.0012 - val_mse: 6.9332e-04\n",
      "Epoch 26/50\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.0010 - mse: 4.9728e-04 - val_loss: 0.0012 - val_mse: 6.8975e-04\n",
      "Epoch 27/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 9.8927e-04 - mse: 4.8993e-04 - val_loss: 0.0012 - val_mse: 6.8388e-04\n",
      "Epoch 28/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 9.5054e-04 - mse: 4.8164e-04 - val_loss: 0.0011 - val_mse: 6.7221e-04\n",
      "Epoch 29/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 9.1640e-04 - mse: 4.7265e-04 - val_loss: 0.0011 - val_mse: 6.6187e-04\n",
      "Epoch 30/50\n",
      "137/137 [==============================] - 0s 4ms/step - loss: 8.8321e-04 - mse: 4.6272e-04 - val_loss: 0.0011 - val_mse: 6.4466e-04\n",
      "Epoch 31/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 8.5309e-04 - mse: 4.5177e-04 - val_loss: 0.0010 - val_mse: 6.2546e-04\n",
      "Epoch 32/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 8.2527e-04 - mse: 4.4004e-04 - val_loss: 9.8071e-04 - val_mse: 6.0229e-04\n",
      "Epoch 33/50\n",
      "137/137 [==============================] - 0s 4ms/step - loss: 7.9962e-04 - mse: 4.2653e-04 - val_loss: 9.4923e-04 - val_mse: 5.8181e-04\n",
      "Epoch 34/50\n",
      "137/137 [==============================] - 0s 4ms/step - loss: 7.7750e-04 - mse: 4.1338e-04 - val_loss: 9.2134e-04 - val_mse: 5.6261e-04\n",
      "Epoch 35/50\n",
      "137/137 [==============================] - 0s 4ms/step - loss: 7.5511e-04 - mse: 4.0018e-04 - val_loss: 8.9591e-04 - val_mse: 5.4656e-04\n",
      "Epoch 36/50\n",
      "137/137 [==============================] - 0s 4ms/step - loss: 7.3331e-04 - mse: 3.8809e-04 - val_loss: 8.7089e-04 - val_mse: 5.3128e-04\n",
      "Epoch 37/50\n",
      "137/137 [==============================] - 0s 4ms/step - loss: 7.1493e-04 - mse: 3.7741e-04 - val_loss: 8.4558e-04 - val_mse: 5.1298e-04\n",
      "Epoch 38/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 6.9547e-04 - mse: 3.6573e-04 - val_loss: 8.2198e-04 - val_mse: 4.9732e-04\n",
      "Epoch 39/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.7789e-04 - mse: 3.5529e-04 - val_loss: 8.0021e-04 - val_mse: 4.8202e-04\n",
      "Epoch 40/50\n",
      "137/137 [==============================] - 0s 4ms/step - loss: 6.6225e-04 - mse: 3.4518e-04 - val_loss: 7.7847e-04 - val_mse: 4.6530e-04\n",
      "Epoch 41/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.4729e-04 - mse: 3.3476e-04 - val_loss: 7.5945e-04 - val_mse: 4.5051e-04\n",
      "Epoch 42/50\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 6.3259e-04 - mse: 3.2406e-04 - val_loss: 7.4036e-04 - val_mse: 4.3558e-04\n",
      "Epoch 43/50\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 6.1932e-04 - mse: 3.1514e-04 - val_loss: 7.2470e-04 - val_mse: 4.2443e-04\n",
      "Epoch 44/50\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 6.0586e-04 - mse: 3.0588e-04 - val_loss: 7.0744e-04 - val_mse: 4.1140e-04\n",
      "Epoch 45/50\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 5.9342e-04 - mse: 2.9692e-04 - val_loss: 6.9536e-04 - val_mse: 4.0168e-04\n",
      "Epoch 46/50\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 5.8245e-04 - mse: 2.8867e-04 - val_loss: 6.8237e-04 - val_mse: 3.9089e-04\n",
      "Epoch 47/50\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 5.7015e-04 - mse: 2.7931e-04 - val_loss: 6.6755e-04 - val_mse: 3.7872e-04\n",
      "Epoch 48/50\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 5.5996e-04 - mse: 2.7113e-04 - val_loss: 6.5520e-04 - val_mse: 3.6771e-04\n",
      "Epoch 49/50\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 5.4982e-04 - mse: 2.6279e-04 - val_loss: 6.4606e-04 - val_mse: 3.6066e-04\n",
      "Epoch 50/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 5.4109e-04 - mse: 2.5609e-04 - val_loss: 6.3485e-04 - val_mse: 3.5188e-04\n",
      "[ 09:31:35] getting statistics\n",
      "--------------------\n",
      "training window 56900\n",
      "Epoch 1/50\n",
      "137/137 [==============================] - 4s 6ms/step - loss: 0.1117 - mse: 0.1052 - val_loss: 0.0152 - val_mse: 0.0127\n",
      "Epoch 2/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0106 - val_loss: 0.0069 - val_mse: 0.0046\n",
      "Epoch 3/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0048 - val_loss: 0.0043 - val_mse: 0.0020\n",
      "Epoch 4/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0055 - mse: 0.0033 - val_loss: 0.0036 - val_mse: 0.0015\n",
      "Epoch 5/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0047 - mse: 0.0026 - val_loss: 0.0031 - val_mse: 0.0012\n",
      "Epoch 6/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0040 - mse: 0.0021 - val_loss: 0.0028 - val_mse: 9.6167e-04\n",
      "Epoch 7/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.0035 - mse: 0.0017 - val_loss: 0.0025 - val_mse: 8.0409e-04\n",
      "Epoch 8/50\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.0030 - mse: 0.0014 - val_loss: 0.0022 - val_mse: 6.6195e-04\n",
      "Epoch 9/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.0026 - mse: 0.0011 - val_loss: 0.0020 - val_mse: 5.4852e-04\n",
      "Epoch 10/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.0022 - mse: 8.8315e-04 - val_loss: 0.0018 - val_mse: 4.8151e-04\n",
      "Epoch 11/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0020 - mse: 7.3018e-04 - val_loss: 0.0016 - val_mse: 4.4722e-04\n",
      "Epoch 12/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0018 - mse: 6.3228e-04 - val_loss: 0.0015 - val_mse: 4.3620e-04\n",
      "Epoch 13/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0016 - mse: 5.7567e-04 - val_loss: 0.0014 - val_mse: 4.4168e-04\n",
      "Epoch 14/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0015 - mse: 5.4781e-04 - val_loss: 0.0013 - val_mse: 4.5269e-04\n",
      "Epoch 15/50\n",
      "137/137 [==============================] - 0s 4ms/step - loss: 0.0014 - mse: 5.3526e-04 - val_loss: 0.0013 - val_mse: 4.6484e-04\n",
      "Epoch 16/50\n",
      "137/137 [==============================] - 0s 4ms/step - loss: 0.0013 - mse: 5.3074e-04 - val_loss: 0.0012 - val_mse: 4.7318e-04\n",
      "Epoch 17/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 5.2802e-04 - val_loss: 0.0011 - val_mse: 4.7836e-04\n",
      "Epoch 18/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 5.2628e-04 - val_loss: 0.0011 - val_mse: 4.8082e-04\n",
      "Epoch 19/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 5.2396e-04 - val_loss: 0.0010 - val_mse: 4.8376e-04\n",
      "Epoch 20/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 5.2318e-04 - val_loss: 9.8886e-04 - val_mse: 4.8386e-04\n",
      "Epoch 21/50\n",
      "137/137 [==============================] - 0s 4ms/step - loss: 0.0010 - mse: 5.2100e-04 - val_loss: 9.4928e-04 - val_mse: 4.8138e-04\n",
      "Epoch 22/50\n",
      "137/137 [==============================] - 0s 4ms/step - loss: 9.7709e-04 - mse: 5.1797e-04 - val_loss: 9.1597e-04 - val_mse: 4.8031e-04\n",
      "Epoch 23/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 9.4470e-04 - mse: 5.1608e-04 - val_loss: 8.8584e-04 - val_mse: 4.7943e-04\n",
      "Epoch 24/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 9.1490e-04 - mse: 5.1448e-04 - val_loss: 8.5608e-04 - val_mse: 4.7595e-04\n",
      "Epoch 25/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 8.8810e-04 - mse: 5.1023e-04 - val_loss: 8.2969e-04 - val_mse: 4.6844e-04\n",
      "Epoch 26/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 8.6639e-04 - mse: 5.0491e-04 - val_loss: 8.0298e-04 - val_mse: 4.5787e-04\n",
      "Epoch 27/50\n",
      "137/137 [==============================] - 0s 4ms/step - loss: 8.4355e-04 - mse: 4.9772e-04 - val_loss: 7.7428e-04 - val_mse: 4.4453e-04\n",
      "Epoch 28/50\n",
      "137/137 [==============================] - 0s 4ms/step - loss: 8.1772e-04 - mse: 4.8618e-04 - val_loss: 7.4397e-04 - val_mse: 4.2372e-04\n",
      "Epoch 29/50\n",
      "137/137 [==============================] - 0s 4ms/step - loss: 7.7676e-04 - mse: 4.5298e-04 - val_loss: 6.8328e-04 - val_mse: 3.6506e-04\n",
      "Epoch 30/50\n",
      "137/137 [==============================] - 0s 4ms/step - loss: 6.7666e-04 - mse: 3.5240e-04 - val_loss: 6.1994e-04 - val_mse: 2.9964e-04\n",
      "Epoch 31/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.3227e-04 - mse: 3.1274e-04 - val_loss: 5.9519e-04 - val_mse: 2.8025e-04\n",
      "Epoch 32/50\n",
      "137/137 [==============================] - 0s 4ms/step - loss: 6.0490e-04 - mse: 2.9352e-04 - val_loss: 5.7278e-04 - val_mse: 2.6508e-04\n",
      "Epoch 33/50\n",
      "137/137 [==============================] - 0s 4ms/step - loss: 5.8155e-04 - mse: 2.7688e-04 - val_loss: 5.5183e-04 - val_mse: 2.4983e-04\n",
      "Epoch 34/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 5.6054e-04 - mse: 2.6189e-04 - val_loss: 5.3294e-04 - val_mse: 2.3543e-04\n",
      "Epoch 35/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 5.4040e-04 - mse: 2.4733e-04 - val_loss: 5.1359e-04 - val_mse: 2.2127e-04\n",
      "Epoch 36/50\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 5.2062e-04 - mse: 2.3306e-04 - val_loss: 4.9364e-04 - val_mse: 2.0728e-04\n",
      "Epoch 37/50\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 5.0057e-04 - mse: 2.1918e-04 - val_loss: 4.7154e-04 - val_mse: 1.9346e-04\n",
      "Epoch 38/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 4.8178e-04 - mse: 2.0583e-04 - val_loss: 4.5178e-04 - val_mse: 1.7968e-04\n",
      "Epoch 39/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.6553e-04 - mse: 1.9359e-04 - val_loss: 4.3558e-04 - val_mse: 1.6818e-04\n",
      "Epoch 40/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 4.5094e-04 - mse: 1.8297e-04 - val_loss: 4.2282e-04 - val_mse: 1.6097e-04\n",
      "Epoch 41/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 4.3759e-04 - mse: 1.7396e-04 - val_loss: 4.1052e-04 - val_mse: 1.5392e-04\n",
      "Epoch 42/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 4.2518e-04 - mse: 1.6590e-04 - val_loss: 3.9797e-04 - val_mse: 1.4568e-04\n",
      "Epoch 43/50\n",
      "137/137 [==============================] - 0s 4ms/step - loss: 4.1467e-04 - mse: 1.5982e-04 - val_loss: 3.8451e-04 - val_mse: 1.3590e-04\n",
      "Epoch 44/50\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 4.0590e-04 - mse: 1.5418e-04 - val_loss: 3.7570e-04 - val_mse: 1.2853e-04\n",
      "Epoch 45/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 3.9872e-04 - mse: 1.5012e-04 - val_loss: 3.6848e-04 - val_mse: 1.2342e-04\n",
      "Epoch 46/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 3.9351e-04 - mse: 1.4801e-04 - val_loss: 3.6208e-04 - val_mse: 1.1920e-04\n",
      "Epoch 47/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 3.8354e-04 - mse: 1.4183e-04 - val_loss: 3.5519e-04 - val_mse: 1.1605e-04\n",
      "Epoch 48/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 3.7866e-04 - mse: 1.3999e-04 - val_loss: 3.5078e-04 - val_mse: 1.1368e-04\n",
      "Epoch 49/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 3.7373e-04 - mse: 1.3757e-04 - val_loss: 3.4419e-04 - val_mse: 1.1019e-04\n",
      "Epoch 50/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 3.6887e-04 - mse: 1.3518e-04 - val_loss: 3.3954e-04 - val_mse: 1.0710e-04\n",
      "[ 09:32:05] getting statistics\n",
      "--------------------\n",
      "training window 59176\n",
      "Epoch 1/50\n",
      "137/137 [==============================] - 3s 5ms/step - loss: 0.1115 - mse: 0.1054 - val_loss: 0.0237 - val_mse: 0.0215\n",
      "Epoch 2/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0185 - mse: 0.0161 - val_loss: 0.0108 - val_mse: 0.0080\n",
      "Epoch 3/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0067 - val_loss: 0.0075 - val_mse: 0.0047\n",
      "Epoch 4/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0044 - val_loss: 0.0061 - val_mse: 0.0036\n",
      "Epoch 5/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0058 - mse: 0.0034 - val_loss: 0.0051 - val_mse: 0.0028\n",
      "Epoch 6/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0049 - mse: 0.0027 - val_loss: 0.0043 - val_mse: 0.0021\n",
      "Epoch 7/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0040 - mse: 0.0019 - val_loss: 0.0034 - val_mse: 0.0015\n",
      "Epoch 8/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0032 - mse: 0.0014 - val_loss: 0.0029 - val_mse: 0.0011\n",
      "Epoch 9/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0027 - mse: 0.0010 - val_loss: 0.0025 - val_mse: 9.1244e-04\n",
      "Epoch 10/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0023 - mse: 8.1416e-04 - val_loss: 0.0022 - val_mse: 8.0632e-04\n",
      "Epoch 11/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0020 - mse: 6.8126e-04 - val_loss: 0.0020 - val_mse: 7.0789e-04\n",
      "Epoch 12/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 5.9739e-04 - val_loss: 0.0018 - val_mse: 6.2651e-04\n",
      "Epoch 13/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0017 - mse: 5.4524e-04 - val_loss: 0.0017 - val_mse: 5.6680e-04\n",
      "Epoch 14/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0016 - mse: 5.1379e-04 - val_loss: 0.0016 - val_mse: 5.2686e-04\n",
      "Epoch 15/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0015 - mse: 4.9302e-04 - val_loss: 0.0015 - val_mse: 4.9360e-04\n",
      "Epoch 16/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0014 - mse: 4.7769e-04 - val_loss: 0.0014 - val_mse: 4.7520e-04\n",
      "Epoch 17/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0013 - mse: 4.6639e-04 - val_loss: 0.0013 - val_mse: 4.6838e-04\n",
      "Epoch 18/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 4.5692e-04 - val_loss: 0.0013 - val_mse: 4.7038e-04\n",
      "Epoch 19/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 4.4919e-04 - val_loss: 0.0012 - val_mse: 4.7606e-04\n",
      "Epoch 20/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 4.4306e-04 - val_loss: 0.0012 - val_mse: 4.8094e-04\n",
      "Epoch 21/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 4.3521e-04 - val_loss: 0.0011 - val_mse: 4.8359e-04\n",
      "Epoch 22/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0010 - mse: 4.2697e-04 - val_loss: 0.0011 - val_mse: 4.8329e-04\n",
      "Epoch 23/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 9.9003e-04 - mse: 4.2059e-04 - val_loss: 0.0011 - val_mse: 4.8383e-04\n",
      "Epoch 24/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 9.4463e-04 - mse: 4.1291e-04 - val_loss: 0.0010 - val_mse: 4.8125e-04\n",
      "Epoch 25/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 9.0092e-04 - mse: 4.0469e-04 - val_loss: 9.7728e-04 - val_mse: 4.7866e-04\n",
      "Epoch 26/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.6026e-04 - mse: 3.9507e-04 - val_loss: 9.4670e-04 - val_mse: 4.7520e-04\n",
      "Epoch 27/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 8.2600e-04 - mse: 3.8398e-04 - val_loss: 9.1648e-04 - val_mse: 4.6626e-04\n",
      "Epoch 28/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.9695e-04 - mse: 3.7351e-04 - val_loss: 8.9331e-04 - val_mse: 4.6123e-04\n",
      "Epoch 29/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.6984e-04 - mse: 3.6256e-04 - val_loss: 8.6762e-04 - val_mse: 4.5153e-04\n",
      "Epoch 30/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.4631e-04 - mse: 3.5210e-04 - val_loss: 8.4666e-04 - val_mse: 4.4320e-04\n",
      "Epoch 31/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 7.2342e-04 - mse: 3.4128e-04 - val_loss: 8.2283e-04 - val_mse: 4.3185e-04\n",
      "Epoch 32/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 7.0171e-04 - mse: 3.3112e-04 - val_loss: 7.9795e-04 - val_mse: 4.1890e-04\n",
      "Epoch 33/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.8100e-04 - mse: 3.1990e-04 - val_loss: 7.7293e-04 - val_mse: 4.0250e-04\n",
      "Epoch 34/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 6.6224e-04 - mse: 3.0862e-04 - val_loss: 7.5116e-04 - val_mse: 3.8882e-04\n",
      "Epoch 35/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 6.4531e-04 - mse: 2.9733e-04 - val_loss: 7.2943e-04 - val_mse: 3.7423e-04\n",
      "Epoch 36/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 6.2936e-04 - mse: 2.8647e-04 - val_loss: 7.0958e-04 - val_mse: 3.5995e-04\n",
      "Epoch 37/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.1425e-04 - mse: 2.7558e-04 - val_loss: 6.9099e-04 - val_mse: 3.4619e-04\n",
      "Epoch 38/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.9814e-04 - mse: 2.6407e-04 - val_loss: 6.7607e-04 - val_mse: 3.3585e-04\n",
      "Epoch 39/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 5.8153e-04 - mse: 2.5264e-04 - val_loss: 6.5699e-04 - val_mse: 3.2353e-04\n",
      "Epoch 40/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 5.6764e-04 - mse: 2.4341e-04 - val_loss: 6.3471e-04 - val_mse: 3.0659e-04\n",
      "Epoch 41/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 5.5575e-04 - mse: 2.3525e-04 - val_loss: 6.1973e-04 - val_mse: 2.9559e-04\n",
      "Epoch 42/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 5.4262e-04 - mse: 2.2620e-04 - val_loss: 6.0580e-04 - val_mse: 2.8655e-04\n",
      "Epoch 43/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 5.2969e-04 - mse: 2.1770e-04 - val_loss: 5.9252e-04 - val_mse: 2.7815e-04\n",
      "Epoch 44/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.1854e-04 - mse: 2.1082e-04 - val_loss: 5.8041e-04 - val_mse: 2.7028e-04\n",
      "Epoch 45/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.0818e-04 - mse: 2.0410e-04 - val_loss: 5.6803e-04 - val_mse: 2.6189e-04\n",
      "Epoch 46/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 4.9887e-04 - mse: 1.9811e-04 - val_loss: 5.5765e-04 - val_mse: 2.5517e-04\n",
      "Epoch 47/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.8981e-04 - mse: 1.9263e-04 - val_loss: 5.4557e-04 - val_mse: 2.4764e-04\n",
      "Epoch 48/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.8204e-04 - mse: 1.8841e-04 - val_loss: 5.3616e-04 - val_mse: 2.4179e-04\n",
      "Epoch 49/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.7264e-04 - mse: 1.8263e-04 - val_loss: 5.2240e-04 - val_mse: 2.3200e-04\n",
      "Epoch 50/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 4.6256e-04 - mse: 1.7630e-04 - val_loss: 5.1288e-04 - val_mse: 2.2681e-04\n",
      "[ 09:32:26] getting statistics\n",
      "--------------------\n",
      "training window 61452\n",
      "Epoch 1/50\n",
      "137/137 [==============================] - 3s 5ms/step - loss: 0.1230 - mse: 0.1167 - val_loss: 0.0377 - val_mse: 0.0355\n",
      "Epoch 2/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0195 - mse: 0.0174 - val_loss: 0.0123 - val_mse: 0.0100\n",
      "Epoch 3/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0127 - mse: 0.0102 - val_loss: 0.0089 - val_mse: 0.0064\n",
      "Epoch 4/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0070 - val_loss: 0.0070 - val_mse: 0.0046\n",
      "Epoch 5/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0077 - mse: 0.0054 - val_loss: 0.0058 - val_mse: 0.0036\n",
      "Epoch 6/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0066 - mse: 0.0044 - val_loss: 0.0050 - val_mse: 0.0029\n",
      "Epoch 7/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 0.0036 - val_loss: 0.0042 - val_mse: 0.0022\n",
      "Epoch 8/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0045 - mse: 0.0026 - val_loss: 0.0034 - val_mse: 0.0016\n",
      "Epoch 9/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0034 - mse: 0.0017 - val_loss: 0.0028 - val_mse: 0.0013\n",
      "Epoch 10/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0027 - mse: 0.0012 - val_loss: 0.0026 - val_mse: 0.0011\n",
      "Epoch 11/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0023 - mse: 9.1105e-04 - val_loss: 0.0024 - val_mse: 0.0010\n",
      "Epoch 12/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 7.8706e-04 - val_loss: 0.0023 - val_mse: 9.6945e-04\n",
      "Epoch 13/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0020 - mse: 7.2282e-04 - val_loss: 0.0021 - val_mse: 9.0515e-04\n",
      "Epoch 14/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 6.8850e-04 - val_loss: 0.0020 - val_mse: 8.3064e-04\n",
      "Epoch 15/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0018 - mse: 6.7172e-04 - val_loss: 0.0019 - val_mse: 7.7390e-04\n",
      "Epoch 16/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0017 - mse: 6.5093e-04 - val_loss: 0.0017 - val_mse: 7.1421e-04\n",
      "Epoch 17/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0016 - mse: 6.0451e-04 - val_loss: 0.0016 - val_mse: 6.2666e-04\n",
      "Epoch 18/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0015 - mse: 5.2420e-04 - val_loss: 0.0014 - val_mse: 5.1192e-04\n",
      "Epoch 19/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 4.6786e-04 - val_loss: 0.0013 - val_mse: 4.5061e-04\n",
      "Epoch 20/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0013 - mse: 4.3365e-04 - val_loss: 0.0012 - val_mse: 4.2197e-04\n",
      "Epoch 21/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 4.0545e-04 - val_loss: 0.0011 - val_mse: 4.0167e-04\n",
      "Epoch 22/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 3.7559e-04 - val_loss: 0.0011 - val_mse: 3.7834e-04\n",
      "Epoch 23/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 9.8731e-04 - mse: 3.4663e-04 - val_loss: 9.5866e-04 - val_mse: 3.4423e-04\n",
      "Epoch 24/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.9637e-04 - mse: 3.1757e-04 - val_loss: 8.5046e-04 - val_mse: 2.9965e-04\n",
      "Epoch 25/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.0876e-04 - mse: 2.8774e-04 - val_loss: 7.5260e-04 - val_mse: 2.5524e-04\n",
      "Epoch 26/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.3337e-04 - mse: 2.6213e-04 - val_loss: 6.7732e-04 - val_mse: 2.2922e-04\n",
      "Epoch 27/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.6669e-04 - mse: 2.4185e-04 - val_loss: 6.1685e-04 - val_mse: 2.1180e-04\n",
      "Epoch 28/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 6.1395e-04 - mse: 2.2534e-04 - val_loss: 5.7178e-04 - val_mse: 1.9937e-04\n",
      "Epoch 29/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.6838e-04 - mse: 2.1003e-04 - val_loss: 5.3372e-04 - val_mse: 1.8712e-04\n",
      "Epoch 30/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.2884e-04 - mse: 1.9551e-04 - val_loss: 5.0296e-04 - val_mse: 1.7847e-04\n",
      "Epoch 31/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 4.9770e-04 - mse: 1.8658e-04 - val_loss: 4.8351e-04 - val_mse: 1.7811e-04\n",
      "Epoch 32/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 4.7086e-04 - mse: 1.7805e-04 - val_loss: 4.6489e-04 - val_mse: 1.7478e-04\n",
      "Epoch 33/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 4.5039e-04 - mse: 1.7023e-04 - val_loss: 4.3862e-04 - val_mse: 1.6153e-04\n",
      "Epoch 34/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 4.3635e-04 - mse: 1.6562e-04 - val_loss: 4.2532e-04 - val_mse: 1.5603e-04\n",
      "Epoch 35/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.2683e-04 - mse: 1.6354e-04 - val_loss: 4.0496e-04 - val_mse: 1.4384e-04\n",
      "Epoch 36/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.1901e-04 - mse: 1.6317e-04 - val_loss: 3.9109e-04 - val_mse: 1.3582e-04\n",
      "Epoch 37/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.1364e-04 - mse: 1.6247e-04 - val_loss: 3.8272e-04 - val_mse: 1.3088e-04\n",
      "Epoch 38/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.1130e-04 - mse: 1.6282e-04 - val_loss: 3.7774e-04 - val_mse: 1.2767e-04\n",
      "Epoch 39/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.0892e-04 - mse: 1.6300e-04 - val_loss: 3.7288e-04 - val_mse: 1.2524e-04\n",
      "Epoch 40/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 4.0651e-04 - mse: 1.6243e-04 - val_loss: 3.7232e-04 - val_mse: 1.2583e-04\n",
      "Epoch 41/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.0680e-04 - mse: 1.6389e-04 - val_loss: 3.6887e-04 - val_mse: 1.2444e-04\n",
      "Epoch 42/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.0439e-04 - mse: 1.6314e-04 - val_loss: 3.6659e-04 - val_mse: 1.2334e-04\n",
      "Epoch 43/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 4.0213e-04 - mse: 1.6244e-04 - val_loss: 3.6348e-04 - val_mse: 1.2254e-04\n",
      "Epoch 44/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 4.0000e-04 - mse: 1.6229e-04 - val_loss: 3.6068e-04 - val_mse: 1.2195e-04\n",
      "Epoch 45/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 3.9861e-04 - mse: 1.6240e-04 - val_loss: 3.5871e-04 - val_mse: 1.2112e-04\n",
      "Epoch 46/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 3.9648e-04 - mse: 1.6206e-04 - val_loss: 3.5730e-04 - val_mse: 1.2085e-04\n",
      "Epoch 47/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 3.9428e-04 - mse: 1.6154e-04 - val_loss: 3.5482e-04 - val_mse: 1.2017e-04\n",
      "Epoch 48/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 3.9235e-04 - mse: 1.6144e-04 - val_loss: 3.5290e-04 - val_mse: 1.1987e-04\n",
      "Epoch 49/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 3.9083e-04 - mse: 1.6152e-04 - val_loss: 3.4923e-04 - val_mse: 1.1919e-04\n",
      "Epoch 50/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 3.8830e-04 - mse: 1.6093e-04 - val_loss: 3.4741e-04 - val_mse: 1.1883e-04\n",
      "[ 09:32:47] getting statistics\n",
      "--------------------\n",
      "training window 63728\n",
      "Epoch 1/50\n",
      "137/137 [==============================] - 3s 5ms/step - loss: 0.1287 - mse: 0.1226 - val_loss: 0.0465 - val_mse: 0.0447\n",
      "Epoch 2/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0236 - mse: 0.0215 - val_loss: 0.0154 - val_mse: 0.0129\n",
      "Epoch 3/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0102 - val_loss: 0.0102 - val_mse: 0.0075\n",
      "Epoch 4/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0069 - val_loss: 0.0081 - val_mse: 0.0055\n",
      "Epoch 5/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0054 - val_loss: 0.0069 - val_mse: 0.0045\n",
      "Epoch 6/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 0.0044 - val_loss: 0.0058 - val_mse: 0.0036\n",
      "Epoch 7/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0056 - mse: 0.0034 - val_loss: 0.0047 - val_mse: 0.0027\n",
      "Epoch 8/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.0043 - mse: 0.0024 - val_loss: 0.0036 - val_mse: 0.0018\n",
      "Epoch 9/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.0032 - mse: 0.0015 - val_loss: 0.0027 - val_mse: 0.0011\n",
      "Epoch 10/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0025 - mse: 0.0011 - val_loss: 0.0022 - val_mse: 7.8951e-04\n",
      "Epoch 11/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0022 - mse: 8.4704e-04 - val_loss: 0.0020 - val_mse: 6.7703e-04\n",
      "Epoch 12/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0020 - mse: 7.6013e-04 - val_loss: 0.0019 - val_mse: 6.6739e-04\n",
      "Epoch 13/50\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.0019 - mse: 7.2325e-04 - val_loss: 0.0018 - val_mse: 6.9551e-04\n",
      "Epoch 14/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0018 - mse: 7.0765e-04 - val_loss: 0.0018 - val_mse: 7.3920e-04\n",
      "Epoch 15/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0017 - mse: 7.0091e-04 - val_loss: 0.0018 - val_mse: 7.7154e-04\n",
      "Epoch 16/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0017 - mse: 6.9690e-04 - val_loss: 0.0018 - val_mse: 7.9328e-04\n",
      "Epoch 17/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0016 - mse: 6.9582e-04 - val_loss: 0.0017 - val_mse: 8.0945e-04\n",
      "Epoch 18/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0016 - mse: 6.9537e-04 - val_loss: 0.0017 - val_mse: 8.1787e-04\n",
      "Epoch 19/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0015 - mse: 6.9661e-04 - val_loss: 0.0016 - val_mse: 8.2735e-04\n",
      "Epoch 20/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0015 - mse: 6.9785e-04 - val_loss: 0.0016 - val_mse: 8.3255e-04\n",
      "Epoch 21/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0014 - mse: 6.9770e-04 - val_loss: 0.0015 - val_mse: 8.3084e-04\n",
      "Epoch 22/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 6.9676e-04 - val_loss: 0.0015 - val_mse: 8.3384e-04\n",
      "Epoch 23/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0014 - mse: 6.9497e-04 - val_loss: 0.0015 - val_mse: 8.3484e-04\n",
      "Epoch 24/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0013 - mse: 6.9296e-04 - val_loss: 0.0015 - val_mse: 8.3545e-04\n",
      "Epoch 25/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0013 - mse: 6.8989e-04 - val_loss: 0.0014 - val_mse: 8.3512e-04\n",
      "Epoch 26/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0013 - mse: 6.8695e-04 - val_loss: 0.0014 - val_mse: 8.3541e-04\n",
      "Epoch 27/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 6.8380e-04 - val_loss: 0.0014 - val_mse: 8.3308e-04\n",
      "Epoch 28/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 6.8096e-04 - val_loss: 0.0013 - val_mse: 8.3112e-04\n",
      "Epoch 29/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 6.7798e-04 - val_loss: 0.0013 - val_mse: 8.2882e-04\n",
      "Epoch 30/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 6.7465e-04 - val_loss: 0.0013 - val_mse: 8.2359e-04\n",
      "Epoch 31/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 6.7066e-04 - val_loss: 0.0013 - val_mse: 8.1984e-04\n",
      "Epoch 32/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 6.6700e-04 - val_loss: 0.0013 - val_mse: 8.1560e-04\n",
      "Epoch 33/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 6.6198e-04 - val_loss: 0.0012 - val_mse: 8.1136e-04\n",
      "Epoch 34/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 6.5706e-04 - val_loss: 0.0012 - val_mse: 8.0288e-04\n",
      "Epoch 35/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 6.5197e-04 - val_loss: 0.0012 - val_mse: 7.9599e-04\n",
      "Epoch 36/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0010 - mse: 6.4718e-04 - val_loss: 0.0012 - val_mse: 7.8604e-04\n",
      "Epoch 37/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0010 - mse: 6.4231e-04 - val_loss: 0.0012 - val_mse: 7.8020e-04\n",
      "Epoch 38/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0010 - mse: 6.3752e-04 - val_loss: 0.0011 - val_mse: 7.7261e-04\n",
      "Epoch 39/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 9.9312e-04 - mse: 6.3222e-04 - val_loss: 0.0011 - val_mse: 7.6766e-04\n",
      "Epoch 40/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 9.7650e-04 - mse: 6.2712e-04 - val_loss: 0.0011 - val_mse: 7.5919e-04\n",
      "Epoch 41/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 9.6085e-04 - mse: 6.2200e-04 - val_loss: 0.0011 - val_mse: 7.5290e-04\n",
      "Epoch 42/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 9.4511e-04 - mse: 6.1662e-04 - val_loss: 0.0011 - val_mse: 7.4425e-04\n",
      "Epoch 43/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 9.3141e-04 - mse: 6.1036e-04 - val_loss: 0.0011 - val_mse: 7.3698e-04\n",
      "Epoch 44/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 9.1883e-04 - mse: 6.0387e-04 - val_loss: 0.0010 - val_mse: 7.2688e-04\n",
      "Epoch 45/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 9.0604e-04 - mse: 5.9696e-04 - val_loss: 0.0010 - val_mse: 7.1924e-04\n",
      "Epoch 46/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 8.9361e-04 - mse: 5.9073e-04 - val_loss: 0.0010 - val_mse: 7.0837e-04\n",
      "Epoch 47/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 8.8079e-04 - mse: 5.8398e-04 - val_loss: 9.9475e-04 - val_mse: 7.0006e-04\n",
      "Epoch 48/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 8.6936e-04 - mse: 5.7701e-04 - val_loss: 9.8055e-04 - val_mse: 6.9023e-04\n",
      "Epoch 49/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 8.5834e-04 - mse: 5.6941e-04 - val_loss: 9.6454e-04 - val_mse: 6.7790e-04\n",
      "Epoch 50/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 8.4682e-04 - mse: 5.6196e-04 - val_loss: 9.5367e-04 - val_mse: 6.6988e-04\n",
      "[ 09:33:09] getting statistics\n",
      "--------------------\n",
      "training window 66004\n",
      "Epoch 1/50\n",
      "137/137 [==============================] - 3s 5ms/step - loss: 0.1175 - mse: 0.1114 - val_loss: 0.0303 - val_mse: 0.0283\n",
      "Epoch 2/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0261 - mse: 0.0239 - val_loss: 0.0148 - val_mse: 0.0124\n",
      "Epoch 3/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0146 - mse: 0.0119 - val_loss: 0.0093 - val_mse: 0.0065\n",
      "Epoch 4/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0066 - val_loss: 0.0068 - val_mse: 0.0043\n",
      "Epoch 5/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0049 - val_loss: 0.0053 - val_mse: 0.0032\n",
      "Epoch 6/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0056 - mse: 0.0035 - val_loss: 0.0042 - val_mse: 0.0023\n",
      "Epoch 7/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0043 - mse: 0.0024 - val_loss: 0.0035 - val_mse: 0.0018\n",
      "Epoch 8/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0019 - val_loss: 0.0030 - val_mse: 0.0015\n",
      "Epoch 9/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0031 - mse: 0.0017 - val_loss: 0.0026 - val_mse: 0.0013\n",
      "Epoch 10/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0015 - val_loss: 0.0023 - val_mse: 0.0011\n",
      "Epoch 11/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0013 - val_loss: 0.0021 - val_mse: 9.6758e-04\n",
      "Epoch 12/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0024 - mse: 0.0012 - val_loss: 0.0019 - val_mse: 8.5284e-04\n",
      "Epoch 13/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0022 - mse: 0.0011 - val_loss: 0.0018 - val_mse: 7.6990e-04\n",
      "Epoch 14/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0020 - mse: 0.0010 - val_loss: 0.0017 - val_mse: 7.1763e-04\n",
      "Epoch 15/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0019 - mse: 9.6080e-04 - val_loss: 0.0016 - val_mse: 6.9544e-04\n",
      "Epoch 16/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0018 - mse: 9.0670e-04 - val_loss: 0.0016 - val_mse: 6.9593e-04\n",
      "Epoch 17/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0017 - mse: 8.6596e-04 - val_loss: 0.0015 - val_mse: 7.0897e-04\n",
      "Epoch 18/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0016 - mse: 8.3609e-04 - val_loss: 0.0015 - val_mse: 7.2142e-04\n",
      "Epoch 19/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0016 - mse: 8.1436e-04 - val_loss: 0.0015 - val_mse: 7.3072e-04\n",
      "Epoch 20/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0015 - mse: 7.9884e-04 - val_loss: 0.0015 - val_mse: 7.4063e-04\n",
      "Epoch 21/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0015 - mse: 7.8561e-04 - val_loss: 0.0014 - val_mse: 7.4587e-04\n",
      "Epoch 22/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 7.7458e-04 - val_loss: 0.0014 - val_mse: 7.5002e-04\n",
      "Epoch 23/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0014 - mse: 7.6418e-04 - val_loss: 0.0014 - val_mse: 7.5250e-04\n",
      "Epoch 24/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0014 - mse: 7.5421e-04 - val_loss: 0.0014 - val_mse: 7.5273e-04\n",
      "Epoch 25/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0013 - mse: 7.4483e-04 - val_loss: 0.0013 - val_mse: 7.4931e-04\n",
      "Epoch 26/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0013 - mse: 7.3536e-04 - val_loss: 0.0013 - val_mse: 7.4841e-04\n",
      "Epoch 27/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0013 - mse: 7.2543e-04 - val_loss: 0.0013 - val_mse: 7.4231e-04\n",
      "Epoch 28/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 7.1510e-04 - val_loss: 0.0013 - val_mse: 7.3234e-04\n",
      "Epoch 29/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 7.0468e-04 - val_loss: 0.0012 - val_mse: 7.1968e-04\n",
      "Epoch 30/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 6.9400e-04 - val_loss: 0.0012 - val_mse: 7.0993e-04\n",
      "Epoch 31/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 6.8144e-04 - val_loss: 0.0012 - val_mse: 6.9587e-04\n",
      "Epoch 32/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.0011 - mse: 6.6719e-04 - val_loss: 0.0011 - val_mse: 6.7651e-04\n",
      "Epoch 33/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 6.5099e-04 - val_loss: 0.0011 - val_mse: 6.5190e-04\n",
      "Epoch 34/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0010 - mse: 6.3388e-04 - val_loss: 0.0010 - val_mse: 6.2353e-04\n",
      "Epoch 35/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.0010 - mse: 6.1467e-04 - val_loss: 9.7972e-04 - val_mse: 5.9499e-04\n",
      "Epoch 36/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 9.6281e-04 - mse: 5.9165e-04 - val_loss: 9.2756e-04 - val_mse: 5.5645e-04\n",
      "Epoch 37/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 9.2240e-04 - mse: 5.6248e-04 - val_loss: 8.7895e-04 - val_mse: 5.1798e-04\n",
      "Epoch 38/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 8.7934e-04 - mse: 5.2942e-04 - val_loss: 8.2921e-04 - val_mse: 4.7897e-04\n",
      "Epoch 39/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 8.3328e-04 - mse: 4.9418e-04 - val_loss: 7.7424e-04 - val_mse: 4.3531e-04\n",
      "Epoch 40/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 7.8655e-04 - mse: 4.5793e-04 - val_loss: 7.2220e-04 - val_mse: 3.9370e-04\n",
      "Epoch 41/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 7.4307e-04 - mse: 4.2332e-04 - val_loss: 6.7519e-04 - val_mse: 3.5474e-04\n",
      "Epoch 42/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 7.0343e-04 - mse: 3.9101e-04 - val_loss: 6.2986e-04 - val_mse: 3.1821e-04\n",
      "Epoch 43/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 6.6543e-04 - mse: 3.5898e-04 - val_loss: 5.9002e-04 - val_mse: 2.8343e-04\n",
      "Epoch 44/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 6.2864e-04 - mse: 3.2767e-04 - val_loss: 5.5291e-04 - val_mse: 2.5323e-04\n",
      "Epoch 45/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.9480e-04 - mse: 2.9884e-04 - val_loss: 5.2165e-04 - val_mse: 2.2670e-04\n",
      "Epoch 46/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 5.6360e-04 - mse: 2.7196e-04 - val_loss: 4.9318e-04 - val_mse: 2.0314e-04\n",
      "Epoch 47/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.3498e-04 - mse: 2.4791e-04 - val_loss: 4.6769e-04 - val_mse: 1.8283e-04\n",
      "Epoch 48/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 5.1005e-04 - mse: 2.2731e-04 - val_loss: 4.4690e-04 - val_mse: 1.6560e-04\n",
      "Epoch 49/50\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 4.8866e-04 - mse: 2.0928e-04 - val_loss: 4.2789e-04 - val_mse: 1.5153e-04\n",
      "Epoch 50/50\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 4.7100e-04 - mse: 1.9495e-04 - val_loss: 4.1183e-04 - val_mse: 1.3933e-04\n",
      "[ 09:33:29] getting statistics\n"
     ]
    }
   ],
   "source": [
    "meas = sliding_window_LSTM(data,30,0.75)\n",
    "measures = meas\n",
    "rmse = round(statistics.mean(measures['rmse']),3)\n",
    "mape = round(statistics.mean(measures['mape']),3)\n",
    "smape = round(statistics.mean(measures['smape']),3)\n",
    "mae = round(statistics.mean(measures['mae']),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cbfc1fd-ef51-4ec0-91fc-ab146ab5efeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.122\n",
      "17.49\n",
      "7.359\n",
      "0.088\n"
     ]
    }
   ],
   "source": [
    "print (rmse)\n",
    "print (mape)\n",
    "print (smape)\n",
    "print (mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de420b7-1676-405b-89d7-bc3a8132035d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
